{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 6: Sequence-to-Sequence Model\n",
    "\n",
    "#### Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyerin, Seo. (hyseo@students.uni-mainz.de)\n",
    "* Yeonwoo, Nam. (yeonam@students.uni-mainz.de)\n",
    "* Yevin, Kim. (kyevin@students.uni-mainz.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this homework we're going to look at an encoder-decoder model.\n",
    "\n",
    "*Total Points: 20P*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "*Task 1: Decide which metric is the better one! Explain your decision.* -> Evaluation: **XX/2**\n",
    "\n",
    "*TASK 2: As always, explain the dataset! (1P)* -> Ev aluation: **XX/1**\n",
    "\n",
    "*TASK 3: Explain what an encoder-decoder structure is! (2P)* -> Evaluation: **XX/2**\n",
    "\n",
    "*TASK 4: How can we use this structure to solve our task? (1P)* -> Evaluation: **XX/1**\n",
    "\n",
    "*TASK 5: Create your vocabulary. (2P)* -> Evaluation: **XX/2**\n",
    "\n",
    "*TASK 6: Create the PyTorch Dataset for the task! (2P)* -> Evaluation: **XX/2**\n",
    "\n",
    "*TASK 7: Create an encoder-decoder LSTM model! (3P)* -> Evaluation: **XX/3**\n",
    "\n",
    "*Task 8: Create a training loop for one epoch. (2P)* -> Evaluation: **XX/2**\n",
    "\n",
    "*TASK 9: Compare the validation accuracy between version 1 and version 2. What is the difference? (1P)* -> Evaluation: **XX/1**\n",
    "\n",
    "*Task 10: Now write the full training loop with multiple epochs and plot the training loss and validation accuracy. (1P)* -> Evaluation: **XX/2**\n",
    "\n",
    "*Task 11: Now calculate the test accuracy with version1 and version2 accuracy! (1P)* -> Evaluation: **XX/1**\n",
    "\n",
    "*Task 12: What are the reasons why a vanilla encoder-decoder RNN is bad in this task? Which modifications could help? (1P)* -> Evaluation: **XX/1**\n",
    "\n",
    "**Total: XX/20**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Good or Bad Metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a more fundamental question: How can we decide which metric is better for a specific task?\n",
    "\n",
    "Assume we have a translation task. Each sentence is now being judged my a human who can speak both languages. The human gives a rating from 1-10. \n",
    "\n",
    "Now you created a new metric called BestMetric. You want to compare your metric vs. other established metrics, such as BLEU. \n",
    "\n",
    "The results are the following:\n",
    "\n",
    "| Translated Sentence | Human Rating | BLEU | BestMetric |\n",
    "| -------------------- | ------------ | ---------- | ---- |\n",
    "| Sentence1            | 8            | 0.82       | 0.80 |\n",
    "| Sentence2            | 7            | 0.78       | 0.81 |\n",
    "| Sentence3            | 3            | 0.50       | 0.70 |\n",
    "| Sentence4            | 9            | 0.95       | 0.90 |\n",
    "| Sentence5            | 1            | 0.25       | 0.65 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Decide which metric is the better one! Explain your decision. (2P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better evaluation should be closer to the human evaluation criteria, so we should evaluate the correlation with the human rating to see which one has a higher correlation coefficient.\n",
    "\n",
    "Here's a formula to calculate the Pearson correlation coefficient of BLEU and BestMetric with Human Rating respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient for BLEU: 0.9914784487581396\n",
      "Pearson Correlation Coefficient for BestMetric: 0.9650800974075744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Human_Rating = [8, 7, 3, 9, 1]\n",
    "BLEU_Val = [0.82, 0.78, 0.50, 0.95, 0.25]\n",
    "BestMetric_Val = [0.80, 0.81, 0.70, 0.90, 0.65]\n",
    "\n",
    "corr_BLEU = np.corrcoef(BLEU_Val, Human_Rating)[0, 1]\n",
    "corr_BestMetric = np.corrcoef(BestMetric_Val, Human_Rating)[0, 1]\n",
    "\n",
    "# Print out the correlation coefficients\n",
    "print(f\"Pearson Correlation Coefficient for BLEU: {corr_BLEU}\")\n",
    "print(f\"Pearson Correlation Coefficient for BestMetric: {corr_BestMetric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, I think BLEU is better because it has a higher correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Morphological Inflection Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will implement a sequence to sequence model to generate inflected forms: The task is to generate the inflected form of a given lemma corresponding to a particular linguistic transformation.\n",
    "\n",
    "<img src=\"06_example.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "Number of training samples: 10000\n",
      "Example sentences:\n",
      "   ['optimieren', 'optimieren', 'V;IND;PRS;3;PL']\n",
      "   ['sabbeln', 'sabbelt', 'V;IND;PRS;2;PL']\n",
      "\n",
      "Dev Data:\n",
      "Number of development samples: 1000\n",
      "\n",
      "Test Data:\n",
      "Number of test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"morphological\"\n",
    "\n",
    "# Define the file paths\n",
    "train_file = os.path.join(data_dir, \"german-train-high.txt\")\n",
    "dev_file = os.path.join(data_dir, \"german-dev.txt\")\n",
    "test_file = os.path.join(data_dir, \"german-uncovered-test.txt\")\n",
    "\n",
    "def read_conll_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_sentence = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:  # Empty line indicates the end of a sentence\n",
    "                if current_sentence:\n",
    "                    data.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "            else:\n",
    "                columns = line.split('\\t')\n",
    "                current_sentence.append(columns)\n",
    "        data += current_sentence\n",
    "    return data\n",
    "\n",
    "# Read data\n",
    "train_data = read_conll_file(train_file)\n",
    "dev_data = read_conll_file(dev_file)\n",
    "test_data = read_conll_file(test_file)\n",
    "\n",
    "print(\"Train Data:\")\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Example sentences:\")\n",
    "for example in train_data[-2:]:  # Displaying the last two sentences for illustration\n",
    "    print(f\"   {example}\")\n",
    "\n",
    "print(\"\\nDev Data:\")\n",
    "print(f\"Number of development samples: {len(dev_data)}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(f\"Number of test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: As always, explain the dataset! (1P) Refer to https://aclanthology.org/K17-2001.pdf**. Be short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains three types of data: \n",
    "\n",
    "1. Lemma: The basic form of a word.\n",
    "2. Inflected Form: the inflected or surface form of a word.\n",
    "3. Inflection: a bundle of morphosyntactic features.\n",
    "\n",
    "Given the reference, the goal of the dataset is that the last column (the inflected form) in the test data is predicted by the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve the task with an encoder-decoder RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3: Explain what an encoder-decoder structure is! Be short. (2P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of an encoder-decoder consists of two main components.\n",
    "- Encoder: Converts the input sentences into vectors, matrices. (ex. LSTM, GRU) (Encoding)\n",
    "- Decoder: Converts the encoded data values into the target language. (Decoding)\n",
    "\n",
    " Thus, an encoder-decoder works by encoding an input sequence into a vector of a certain size and decoding the vector into an output sequence through a decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: How can we use this structure to solve our task? (1P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve our goal in this task (generating inflections from lemmas), the encoder-decoder structure can be used as follows. \n",
    " The encoder takes a sequence of lemmas as input and generates a fixed-size context vector containing their semantic information. The decoder uses this context vector to generate a transformed form.\n",
    "\n",
    " In other words, the encoder captures the semantics of the lemmas and generates a context vector. The decoder generates a transformed form based on the context vector from the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can create our dataset and a model, we need to encode all characters AND the _morphosyntactic features_ as indices (our vocabulary). Later, we will then create an embedding for each index - like we did for the last homeworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5: Create your vocabulary. (2P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Your code here.\n",
    "\n",
    "Create a vocabulary over your LOWER-CASED text (character-level) and the UPPER-CASED morphosyntactic features.\n",
    "\n",
    "For the text (the lemma and Inflected form), we encode them on character-level,\n",
    "i.e. each character has an index, e.g. \"a\" -> 25.\n",
    "\n",
    "For the morphosyntactic features, we encode them directly, i.e. each inflection has an\n",
    "index, e.g. \"IND\" -> 13.\n",
    "\n",
    "PRE-append special tokens to your vocabulary. \n",
    "Sort the rest of the vocab alphabetically (already written):\n",
    "# This is my order: Special tokens + inflection + characters created from the text\n",
    "characters = sorted(characters)\n",
    "tags = sorted(tags) \n",
    "vocab = special_tokens+tags+characters\n",
    "\n",
    "'''\n",
    "\n",
    "# We also have special tokens. <sep> is a separate token:\n",
    "special_tokens = ['<s>', '</s>', '<sep>']\n",
    "\n",
    "# To keep it simple, we collect our vocabulary from the train, dev and test dataset\n",
    "all = train_data + dev_data + test_data\n",
    "\n",
    "characters = set() # characters holds all lower-cased unique characters that appear in the text\n",
    "tags = set() # Holds all upper-cased unique morphosyntactic feature (inflection)\n",
    "\n",
    "for data in all:\n",
    "    characters.update(list(data[0].lower())) #Lemma\n",
    "    characters.update(list(data[1].lower()))  #Inflected form\n",
    "\n",
    "    tag_components = data[2].upper().split(';')\n",
    "    tags.update(tag_components)\n",
    "\n",
    "# This is my order: Special tokens + inflection + characters created from the text (unordered\n",
    "characters = sorted(list(characters))\n",
    "tags = sorted(list(tags))\n",
    "\n",
    "vocab = special_tokens + tags + characters\n",
    "\n",
    "# Dictionary mapping from word (character and the inflection) to index\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "index_to_word = {idx: word for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert word_to_index[\"GEN\"] == 8\n",
    "assert word_to_index[\"a\"] == 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our vocabulary, we can create our PyTorch dataset for this task.\n",
    "\n",
    "Remember, our model has to learn to do the following: Given ['Reflektion', 'N;ACC;PL'], output: 'Reflektionen'.\n",
    "\n",
    "How to we construct the input and output?\n",
    "\n",
    "The input for the model is the lemma and the inflected form concatenated:\n",
    "- '\\<s\\>' + lemma (as indices) + '\\<sep\\>' + morphosyntactic features (as indices) + '\\</s\\>'\n",
    "\n",
    "The output for the model is the inflected form\n",
    "- '\\<s\\>' + inflected form (as indices) + '\\</s\\>'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6: Create the PyTorch Dataset for the task! (2P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "'''\n",
    "Your Code Here.\n",
    "\n",
    "Create the PyTorch Dataset for the task!\n",
    "\n",
    "The input is the lemma and the inflected form concatenated:\n",
    "'<s>' + lemma (as indices) + '<sep>' + morphosyntactic features (as indices) + '</s>'\n",
    "\n",
    "The output is the inflected form\n",
    "'<s>' + inflected form (as indices) + '</s>'\n",
    "\n",
    "'''\n",
    "\n",
    "class InflectionDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        root_form, inflected_form, morphological_info = self.data[idx]\n",
    "\n",
    "        # Start, end, and separator tokens\n",
    "        sos_id = [word_to_index['<s>']]\n",
    "        eos_id = [word_to_index['</s>']]\n",
    "        sep_id = [word_to_index['<sep>']]\n",
    "\n",
    "        # Convert characters and morphological_info to numerical representations using word_to_index\n",
    "        input_root_morph = sos_id + [word_to_index[char] for char in root_form.lower()] + sep_id + [word_to_index[tag] for tag in morphological_info.split(';')] + eos_id\n",
    "        output_inflected = sos_id + [word_to_index[char] for char in inflected_form.lower()] + eos_id\n",
    "\n",
    "        # Convert to Input Tensor and Output tensor\n",
    "        input_root_morph = torch.tensor(input_root_morph, dtype=torch.long)\n",
    "        output_inflected = torch.tensor(output_inflected, dtype=torch.long)\n",
    "\n",
    "        return input_root_morph, output_inflected\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = InflectionDataset(train_data)\n",
    "dev_dataset = InflectionDataset(dev_data)\n",
    "test_dataset = InflectionDataset(test_data)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Example usage:\n",
    "example_idx = 0\n",
    "input_sequence, target_sequence = train_dataset[example_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the high dataset\n"
     ]
    }
   ],
   "source": [
    "test_dataset = InflectionDataset([['Reflektion', 'Reflektionen', 'N;ACC;PL'], ['Scherz', 'Scherzes', 'N;GEN;SG']])\n",
    "input_root_morph, output_inflected = test_dataset[0]\n",
    "if \"medium\" in train_file:\n",
    "    print(\"You are using the medium dataset\")\n",
    "    # ASSERT FOR MEDIUM TRAINING SET\n",
    "    assert torch.equal(input_root_morph, torch.tensor([0, 41, 28, 29, 35, 28, 34, 43, 32, 38, 37,  2, 11,  6, 14,  1]))\n",
    "    assert torch.equal(output_inflected, torch.tensor([0, 41, 28, 29, 35, 28, 34, 43, 32, 38, 37, 28, 37,  1]))\n",
    "elif \"high\" in train_file:\n",
    "    print(\"You are using the high dataset\")\n",
    "    # ASSERT FOR HIGH TRAINING SET\n",
    "    assert torch.equal(input_root_morph, torch.tensor([0, 41, 28, 29, 35, 28, 34, 43, 32, 38, 37,  2, 11,  6, 14,  1]))\n",
    "    assert torch.equal(output_inflected, torch.tensor([0, 41, 28, 29, 35, 28, 34, 43, 32, 38, 37, 28, 37,  1]))\n",
    "else:\n",
    "    print(\"low not done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Input: tensor([ 0, 41, 28, 29, 35, 28, 34, 43, 32, 38, 37,  2, 11,  6, 14,  1])\n",
      "Actual Output: tensor([ 0, 41, 28, 29, 35, 28, 34, 43, 32, 38, 37, 28, 37,  1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Input:\", input_root_morph)\n",
    "print(\"Actual Output:\", output_inflected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset, we have to create our model.\n",
    "\n",
    "We will use an encoder-decoder LSTM model WITHOUT attention. This simplifies the architecture, but is not the best choice for (see last task)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7: Create an encoder-decoder LSTM model! (3P)**\n",
    "\n",
    "(See the code for hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "'''\n",
    "Your Code here.\n",
    "\n",
    "\n",
    "Create an encoder-decoder LSTM model!\n",
    "\n",
    "\n",
    "Try to go along the comments that I wrote.\n",
    "\n",
    "\n",
    "'''\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "       \n",
    "        # Use LSTM\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
    "       \n",
    "        # Use Dropout\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Get the embeddings for the input\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        # Initialize initial hidden and cell states\n",
    "        h0 = torch.zeros(1, input.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(1, input.size(0), self.hidden_size)\n",
    "        \n",
    "        # Forward through your rnn\n",
    "        ooutput, (hidden, cell) = self.rnn(embedded, (h0, c0))\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "# Now we create our decoder RNN\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "\n",
    "        # We will share the embeddings with our encoder!\n",
    "        self.embedding = None\n",
    "\n",
    "\n",
    "        # Again define RNN (LSTM Module)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "\n",
    "        # Now we need a linear layer to classify over our vocabulary\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        # This function just does one step of a decoder given the input and hidden (context) vector\n",
    "\n",
    "\n",
    "        # Get the embeddings for the input\n",
    "        output = self.dropout(self.embedding(input))\n",
    "\n",
    "\n",
    "        # Forward through your lstm\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "\n",
    "        # Use your linear layer for classification (keep the logits)\n",
    "        output = self.out(output.squeeze(1))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None, max_length=50):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "\n",
    "\n",
    "        # We start with the start-of-sentence token\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long).fill_(0)\n",
    "\n",
    "\n",
    "        # Current context vector\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "\n",
    "        # Now we predict step by step the next token\n",
    "        for i in range(max_length):\n",
    "            # Use your forward_step to get the output and the hidden (context) vector\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "\n",
    "\n",
    "            # Save the output\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "\n",
    "            # Now it is getting tricky: When we have the ground truth, we\n",
    "            # do not want to keep predicting the next token based on our predicted output as input\n",
    "            # we want to use the real output token to predict the next token\n",
    "            if target_tensor is not None:\n",
    "                # Case 1: We have the ground truth\n",
    "                if target_tensor.shape[-1] == i + 1:\n",
    "                    # This ensures that we stop when we exhausted the GT\n",
    "                    break\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "           \n",
    "            else:\n",
    "                # Case 2: Use its own predictions as the next input\n",
    "                # based on the decoder_output, get the predicted token as index\n",
    "                # Hint: no need to calculate the probability, just get the highest logit index\n",
    "                # as prediction\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.detach()  # To save space, use .detach() at the end\n",
    "\n",
    "\n",
    "            # Check if the end-of-sequence token is predicted\n",
    "            if decoder_input.item() == 1:  # Assuming 1 is the index for the end token\n",
    "                break\n",
    "\n",
    "\n",
    "        # Now, concatenate all decoder_outputs\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, None  # We return `None` for consistency in the training loop\n",
    "\n",
    "\n",
    "    def share_embedding(self, encoder):\n",
    "        # Share the embedding with the encoder\n",
    "        self.embedding = encoder.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our encoder-decoder model, we need to create the training loop and a validation loop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8: Create a training loop for one epoch based on your model implementation. Return the training loss. (2P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Your code here.\n",
    "\n",
    "Create a training loop for ONE epoch based on your model implementation.\n",
    "\n",
    "See the next-next cell to see the full training loop.\n",
    "\n",
    "Return the training loss.\n",
    "\n",
    "'''\n",
    "\n",
    "# Assume the following inputs for your training epoch loop.\n",
    "def training_epoch(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer):\n",
    "    # Hint: you now have an encoder optimizer AND and decoder optimizer. \n",
    "    # Both have to be called with .zero_grad() and .step()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    # Set the models to train mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for data in train_loader:\n",
    "        # Your Code\n",
    "        # Extract input and target data\n",
    "        input_data, target_data = data\n",
    "        \n",
    "        # Zero the gradients for both optimizers\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        encoder_output = encoder(input_data)\n",
    "        decoder_output = decoder(encoder_output)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(decoder_output, target_data)\n",
    "        \n",
    "        # Perform backpropagation and optimization\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        # Accumulate the total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate the average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return avg_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the training loop, we only need the validation loop.\n",
    "\n",
    "This time, you do not have to write the validation loop yourself. I will give you two validation loops and your task is to tell me what the difference between the metrics are. Both calculate accuracies, but based on what exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Version:\n",
    "def validate(encoder, decoder, val_loader, criterion, print_frequence=100000):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    #total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, data in enumerate(val_loader):\n",
    "            input_tensor, target_tensor = data\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = decoder_outputs.max(2)\n",
    "            correct_predictions += (predicted == target_tensor).sum().item()\n",
    "            total_samples += target_tensor.size(0) * target_tensor.size(1)\n",
    "\n",
    "            # Just for printing purposes (ignore)\n",
    "            if index % print_frequence == 0:\n",
    "                # Convert tensor to words\n",
    "                words_input = [index_to_word[idx.item()] for idx in input_tensor[0]]\n",
    "                sep_index = words_input.index('<sep>')\n",
    "                input_str = ''.join(words_input[:sep_index]) \n",
    "                input_str += '<sep>' + ';'.join(words_input[sep_index+1:-1]) + '</s>'\n",
    "                words_target = [index_to_word[idx.item()] for idx in target_tensor[0]]\n",
    "                words_predicted = [index_to_word[idx.item()] for idx in predicted[0]]\n",
    "                print(f\"\\nExample {index}\")\n",
    "                print(f\"Input: {input_str}\")\n",
    "                print(f\"Target: {''.join(words_target)}\")\n",
    "                print(f\"Predicted: {''.join(words_predicted)}\")\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# Second Version:\n",
    "def validate_hard(encoder, decoder, val_loader, criterion, print_frequence=10):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, data in enumerate(val_loader):\n",
    "            input_tensor, target_tensor = data\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, None)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = decoder_outputs.max(2)\n",
    "            if predicted.shape == target_tensor.shape and torch.equal(predicted, target_tensor):\n",
    "                correct_predictions += 1\n",
    "            total_samples += target_tensor.size(0)\n",
    "\n",
    "            # Just for printing purposes (ignore)\n",
    "            if index % print_frequence == 0:\n",
    "                # Convert tensor to words\n",
    "                words_input = [index_to_word[idx.item()] for idx in input_tensor[0]]\n",
    "                sep_index = words_input.index('<sep>')\n",
    "                input_str = ''.join(words_input[:sep_index]) \n",
    "                input_str += '<sep>' + ';'.join(words_input[sep_index+1:-1]) + '</s>'\n",
    "                words_target = [index_to_word[idx.item()] for idx in target_tensor[0]]\n",
    "                words_predicted = [index_to_word[idx.item()] for idx in predicted[0]]\n",
    "                print(f\"\\nExample {index}\")\n",
    "                print(f\"Input: {input_str}\")\n",
    "                print(f\"Target: {''.join(words_target)}\")\n",
    "                print(f\"Predicted: {''.join(words_predicted)}\")\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy\n",
    "\n",
    "def transform_input_tensor_to_string(input_tensor):\n",
    "    words_input = [index_to_word[idx.item()] for idx in input_tensor[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 9: Compare the validation accuracy between version 1 and version 2. What is the difference? (1P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Both validate functions are used to measure the performance (accuracy) of a model, but they differ in their approach.\n",
    "\n",
    " In the first version, the accuracy is calculated by computing the agreement between the overall prediction and the actual target sequence in each sample: it compares all the predictions and targets in each batch, considers each match to be an accurate prediction, and returns the accuracy by calculating the percentage of tokens that match. \n",
    " \n",
    " The second version, however, checks whether the entire sequence is correctly matched in each sample, incrementing the accuracy whenever the entire sequence is matched in each batch, thus calculating a binary accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 10: Now write the full training loop with multiple epochs and plot the training loss and validation accuracy. (2P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 45\u001b[0m\n\u001b[0;32m     40\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Your Code\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Call your training_epoch()\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Call my validate() function \u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# I am printing one example per epoch, \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 33\u001b[0m, in \u001b[0;36mtraining_epoch\u001b[1;34m(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer)\u001b[0m\n\u001b[0;32m     30\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m decoder(encoder_output)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Yevin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Yevin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m, in \u001b[0;36mEncoderRNN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Get the embeddings for the input\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Initialize initial hidden and cell states\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Yevin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Yevin\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Yevin\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Yevin\\lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "'''\n",
    "Your code here.\n",
    "\n",
    "Write the full training loop with multiple epochs!\n",
    "\n",
    "Collect the training loss (per sample) and the validation accuracy. Plot both.\n",
    "\n",
    "'''\n",
    "\n",
    "# define encoder, decoder\n",
    "# I used hidden_size=64\n",
    "input_size = len(data)\n",
    "hidden_size = 64 \n",
    "# Feel free to adjust\n",
    "encoder = EncoderRNN(input_size, hidden_size)\n",
    "decoder = DecoderRNN(hidden_size, input_size)\n",
    "\n",
    "# Share the embeddings\n",
    "decoder.share_embedding(encoder)\n",
    "\n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# One epoch takes 1 minute on my laptop\n",
    "# Either reduce the size of the model or reduce the data amount (medium training data)\n",
    "# You can also increase the epochs to get the best model possible\n",
    "num_epochs = 5\n",
    "\n",
    "# Lists to store the loss and accuracy for each epoch\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Define criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Your Code\n",
    "    # Call your training_epoch()\n",
    "    train_loss = training_epoch(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    # Call my validate() function \n",
    "    # I am printing one example per epoch, \n",
    "    val_accuracy = validate(encoder, decoder, val_loader, criterion)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    # you can change that if you want in the validation function\n",
    "\n",
    "    # Use training loss per sample\n",
    "    print(f'Training Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    print(f'Validation Epoch [{epoch + 1}/{num_epochs}], Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Plot everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 11: Now calculate the test accuracy with version1 and version2 accuracy! (1P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "'''\n",
    "Your code here.\n",
    "Calculate the test accuracy with version1 and version2 accuracy!\n",
    "\n",
    "'''\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_accuracy_version_1 = validate(encoder, decoder, test_loader, criterion)\n",
    "    print(f'Test Accuracy for Version 1: {test_accuracy_version_1:.4f}')\n",
    "\n",
    "    test_accuracy_version_2 = validate_hard(encoder, decoder, test_loader, criterion)\n",
    "    print(f'Test Accuracy for Version 2: {test_accuracy_version_2:.4f}')\n",
    "\n",
    "    \n",
    "    # Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 12: What are the reasons why a vanilla encoder-decoder RNN is bad in this task? Which modifications could help? (1P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vanilla encoder-decoder RNN suffers from the Long-Term Dependency Problem. This is the disadvantage that as the length of the sequence increases, it does not retain the information of the previous cell while moving on to the next cell. To compensate for this, we can use the \"Attention\" technique. It is a technique that reflects the semantic association information between words in the input sequence by 'paying attention' to the input of the encoder that is most relevant to the decoder cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 7: Crowdsourcing\n",
    "#### Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yevin Kim (kyevin@students.uni-mainz.de)\n",
    "**Only this homework: Please submit individually, as working in pairs or groups doesn't make much sense content-wise. You can still discuss the homework with your classmates, but your solutions shouldn't be identical.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reach 20 points on this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this homework we're going to revisit what we've learned about crowdsourcing. Specifically, you will produce annotation instructions for a task of your choice. This exercise looks short, but some of the tasks take time, so don't get started too late!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have questions, you can reach out via mail: minhducbui@uni-mainz.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Theoretical Background\n",
    "\n",
    "In this section, we'll ask you to answer some free-response questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "1. Describe (=name and say 1-3 sentences about each) the 5 criteria needed in order for collective thought or action to be collective intelligence (according to James Surowiecki). (2P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": According to James Surowiecki, there are five criteria for collective thought or action to be collective intelligence. (Independence, Decentralised, Diversity of Opinion, Aggregation, Trust)\n",
    " First, \"Independence\" means that multiple opinions should be not affected by each other. \"Decentralised\" means that the opinions should not be affiliated with a group, such as a location or organisation; \"Diversity of Opinion\" means that we can assume that the crowdworker pool is a diverse set - a group of opinions that is biased one way or the other cannot be called collective intelligence; \"Aggregation\" emphasises that all responses must be statistically (or otherwise) combined to be collective intelligence; and \"Trust\" means that the person giving the opinion has no reason or basis to give a deliberately wrong answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Name 3 differences between crowdsourcing and expert annotation. (2P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": According to crowdsourcing platforms like MTurk, the difference between crowdsourcing and expert annotation is how the work is divided. When repetitive and simple tasks are outsourced through crowdsourcing, companies are able to invest their time and resources in more complex tasks. In addition, the flexibility to increase or decrease the number of people available to meet the company's needs is also the specific feature of crowdsourcing. As a result, leveraging the skills of distributed workers is a more cost-effective way of doing things compared to using a dedicated expert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Name 2 important things to keep in mind when writing annotation instructions for crowdsourcing. (2P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": The first thing to keep in mind is that you need to give specific instructions to your crowdsourced workers so that there is no confusion while they are working on the task. It is important to distinguish between right and wrong answers and include examples to avoid confusion. \n",
    " Also, if the HIT is not doable because of missing data or other problems, you should clearly explain the expected outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "source": [
    "## Section 2: Writing Annotation Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We'll work with the dataset described in this paper: https://arxiv.org/pdf/2204.09652.pdf\n",
    "Please read the paper carefully and summarize it in 5-10 sentences. What is the gap with regards to past work, that the paper is trying to fill? What are the main contributions of the paper? (3P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": The paper aims to address a significant gap in past work concerning the analysis of classroom discourse by introducing the TalkMoves dataset. Previous limitations in accessing classroom recordings due to privacy concerns hindered researchers from capturing the unique educational dialogues specific to classroom environments, leading to a scarcity of datasets reflecting these interactions.\n",
    "\n",
    " The primary contribution lies in the creation of the TalkMoves dataset, comprising over 500 annotated transcripts of discourse in elementary, middle, and high school math classes. This dataset stands out as the only publicly available resource aligned with the accountable talk framework, annotated using protocols to ensure consistency and accuracy in the annotations.\n",
    "\n",
    " Overall, the paper's contribution bridges the gap by offering a resource that enables in-depth analysis of classroom discourse, opening opportunities for researchers interested in natural language processing and education. It resolves past limitations in accessibility and sharing, prioritizing wider availability within the research community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "2. Download the data from the repository belonging to the paper and take a look at *Ladder problem 1_Grade 7.xlsx*. The goal of this exercise is to collect data that's suitable for building a model for a *sequence classification* task and this dataset. A naive example (don't do this, it's pretty boring :)) would be to annotate each utterance as being a question or not. Think about which sequence classification tasks you know (also: feel free to ask Google for more!) and which sequence classification task would be interesting to you. (Don't choose any of the ones the data has already been annotated for.) Describe in 2-5 sentences which task you choose and why! (2P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": The most commonly used classification in sequence categorisation is that of emotion. Of course, since the given dataset contains utterances in the context of a \"maths class\", it may be inappropriate to classify them into categories such as Joy/Sadness/Anger/Surprise/Fear, which are common in everyday life. However, analysing the students' emotions when the teacher provides new information to the students will help to ensure that the classroom environment is positive and that ambiguities are resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "3. Keeping in mind everything you know about how to write annotation instructions for crowdsourcing: write high-quality instructions for your future annotators and your task. Make a copy of these annotation instructions, such that you have one that will stay unaltered and one you can update. (2P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction of Sentiment analyzing classroom utterances**\n",
    "\n",
    "- Your task is to read a given dataset and annotate the utterances by identifying the emotions they contain.\n",
    "- Tag has the following categories\n",
    "\t* *1 - None / Simple Informing*.\n",
    "\t- Corresponds to utterances that contain little emotion or are simply informative.\n",
    "\t* *2 - Positive*\n",
    "\t- Corresponds to utterances that contain a positive emotion, such as joy or pleasure. For example, a response that indicates a complete understanding of the information given may also fall into this category.\n",
    "\t* *3 - Confused*\n",
    "\t- Corresponds to utterances that contain confusion. For example, a reaction of asking for clarification because you don't understand the information could also fall into this category.\n",
    "\t* *4 - Mixed*\n",
    "\t- When a single sentence provided contains a complex emotion, it falls into this category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Annotate the first 200 utterances (rows; column E) from *Ladder problem 1_Grade 7.xlsx* and *Ladder problem 2_Grade 7.xlsx* according to your annotation instructions. (200 total, not 200 each.) When in doubt about an example, update your original annotation instructions to clarify. Submit the annotated examples (3P) and the updated annotation instructions (2P) together with the unaltered version of your annotation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": *I have separated the annotations into First Task and Second Task tabs in the zipped excel file together.*\n",
    "\n",
    "***Edited* Instruction of Comprehension analyzing classroom utterances**\n",
    "- Your task is to read a given dataset and annotate the utterances by identifying the emotions they contain.\n",
    "- Tag has the following categories\n",
    "    * *1 - None / Simple Informing*\n",
    "    * It corresponds to utterances that contain little emotion or are simply informative.\n",
    "    * ex1) \"It was seventeen and since five is half of ten, five times two is ten, so I just multiplied the number of rods by two and I got thirty-four for seventeen rods.\" - just informing\n",
    "    * ex2) \"So let's see.\" - no emotion\n",
    "    * *2 - Comprehension*\n",
    "    * It corresponds to an utterance about a reaction to understanding the information provided in a previous utterance.\n",
    "    * ex) \"Ah, I got an idea.\", \"So out of this hundred, you chose ten, right?\"\n",
    "    * *3 - Confused*\n",
    "    * An utterance that is confusing because it does not accurately understand the information previously provided.\n",
    "    * ex) \"Uh, uh, again, again, slowly.\", \"I donâ€™t know now.\"\n",
    "\n",
    "*To achieve what I was aiming for, I made some changes to the instructions and category organisation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "5. Compare the two versions of your annotation instructions. Have they changed (much)? Why yes or why not? Talk about your experience (2-5 sentences, 2P)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": When I first wrote the instructions and annotated them, I felt that the tags were unclear and would not help me achieve my goal. Therefore, I clarified the categories and made distinctions based on the \"level of understanding\" between students and teachers. Also, I thought it would be better to give examples from the dataset rather than just a brief description of the example, so I included an example sentence. However, I was still confused by the fact that the sequence classification I assigned in the first place was not a tag that can be distinguished by looking at a specific single utterance, but a contextual one. I think I could have made a better sequence classification if I had considered this aspect earlier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

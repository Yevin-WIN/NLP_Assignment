{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 10: Cross-Lingual Transfer & Transfer Learning\n",
    "#### Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyerin, Seo. (hyseo@students.uni-mainz.de)\n",
    "* Yeonwoo, Nam. (yeonam@students.uni-mainz.de)\n",
    "* Yevin, Kim. (kyevin@students.uni-mainz.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reach 20 points on this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this homework, we will try to improve our model by using transfer learning and cross-lingual transfer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have questions, you can reach out via mail: minhducbui@uni-mainz.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "*Task 1:* Explain what cross-lingual transfer is (e.g. how it works, why it works). Explain how you would apply crosslingual transfer for our task (given the above datasets)? XX/3\n",
    "\n",
    "*Task 2: Train on the english dataset!* -> Evaluation: XX/2\n",
    "\n",
    "*Task 3: Explain your results! (2P)* -> Evaluation: XX/2\n",
    "\n",
    "*Task 4:* Explain what transfer learning and multi-task learning is (e.g. how it works, why it works). -> Evaluation: XX/3\n",
    "\n",
    "*Task 5:* Propose one task. -> Evaluation: XX/2\n",
    "\n",
    "*Task 6:* Explain whether this task could be beneficial for the main task or not! XX/2\n",
    "\n",
    "*Task 7:* Create the dataset for the above task! -> Evaluation: XX/3\n",
    "\n",
    "*TASK 8: Now train the model! (3P)* -> Evaluation: XX/3\n",
    "\n",
    "\n",
    "**Total: XX/20**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the inflection data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"morphological\"\n",
    "\n",
    "# Define the file paths\n",
    "train_file = os.path.join(data_dir, \"english-train-medium.txt\")\n",
    "dev_file = os.path.join(data_dir, \"english-dev.txt\")\n",
    "test_file = os.path.join(data_dir, \"english-uncovered-test.txt\")\n",
    "\n",
    "def read_conll_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_sentence = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:  # Empty line indicates the end of a sentence\n",
    "                if current_sentence:\n",
    "                    data.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "            else:\n",
    "                columns = line.split('\\t')\n",
    "                current_sentence.append(columns)\n",
    "        data += current_sentence\n",
    "    return data\n",
    "\n",
    "# Read data\n",
    "train_data_raw = read_conll_file(train_file)\n",
    "dev_data = read_conll_file(dev_file)\n",
    "# We are going to reduce the amount of dev data\n",
    "dev_data = dev_data[:50]\n",
    "test_data = read_conll_file(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the following two code cells carefully and understand what they are doing!\n",
    "\n",
    "You are given the following datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small training dataset amount for your main task\n",
    "train_data = train_data_raw[:100]\n",
    "\n",
    "# Transfer Learning dataset\n",
    "transferlearning_train_data = train_data_raw[100:]\n",
    "\n",
    "# Cross-Lingual Dataset\n",
    "train_file = os.path.join(data_dir, \"german-train-medium.txt\")\n",
    "crosslingual_train_data = read_conll_file(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the following scripts (from Homework 09):\n",
    "\n",
    "Training Script on the inflection task and calculating the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_metric\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "\n",
    "def compute_metrics(preds):\n",
    "    output, labels = preds\n",
    "    logits = output[0]\n",
    "    logits = torch.tensor(logits)\n",
    "    labels = torch.tensor(labels)\n",
    "    predictions = logits.argmax(-1)\n",
    "\n",
    "    # Replace all occurrences of -100 with 0 in labels\n",
    "    predictions = torch.where(labels != -100, predictions, torch.tensor(0))\n",
    "    labels = torch.where(labels != -100, labels, torch.tensor(0))\n",
    "    \n",
    "    correct_sequences = torch.all(predictions == labels, dim=1)\n",
    "\n",
    "    accuracy = torch.mean(correct_sequences.float())\n",
    "\n",
    "    return {\"accuracy\": accuracy.item()}\n",
    "\n",
    "    \n",
    "# Custom PyTorch dataset with pre-tokenized data\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.tokenized_data = tokenized_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.tokenized_data[\"input_ids\"][idx],\n",
    "            \"labels\": self.tokenized_data[\"label\"][idx]\n",
    "        }\n",
    "\n",
    "def transform_to_token_ids(data, tokenizer):\n",
    "    # Initialize the PyTorch dictionary\n",
    "    tokenized = {\n",
    "        \"input_ids\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "    # Loop through raw data to tokenize and create training data\n",
    "    for example in data:\n",
    "        # Concatenate the first and third elements in the example list with a space\n",
    "        input_text = example[0] + \" \" + example[2]\n",
    "        \n",
    "        # Tokenize the input text\n",
    "        tokens = tokenizer(input_text, return_tensors='pt')\n",
    "        \n",
    "        input_ids = tokens['input_ids'].squeeze()#.tolist()\n",
    "        \n",
    "        # Get the label (using example[1])\n",
    "        label = tokenizer(example[1], return_tensors='pt')['input_ids'].squeeze()#.tolist()\n",
    "        \n",
    "        # Append to the PyTorch dictionary\n",
    "        tokenized['input_ids'].append(input_ids)\n",
    "        tokenized['label'].append(label)\n",
    "    return tokenized\n",
    "\n",
    "def training_inflection(model, train_data, dev_data=dev_data, learning_rate=5e-3):\n",
    "    # Create the PyTorch dataset\n",
    "    train_tokenized = transform_to_token_ids(train_data, tokenizer)\n",
    "    train_dataset = CustomDataset(train_tokenized)\n",
    "    \n",
    "    dev_tokenized = transform_to_token_ids(dev_data, tokenizer)\n",
    "    dev_dataset = CustomDataset(dev_tokenized)\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"./output\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=1,\n",
    "        num_train_epochs=3,\n",
    "        logging_steps=60,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=60,  # Number of steps before evaluation\n",
    "        learning_rate=learning_rate, \n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        #data_collator=data_collator,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "    \n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "def test_accuracy(model, test_data):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    batch_size = 1\n",
    "    log_interval = 10\n",
    "    test_tokenized = transform_to_token_ids(test_data, tokenizer=tokenizer)\n",
    "    test_dataset = CustomDataset(test_tokenized)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_dataloader):\n",
    "            # Tokenize and prepare inputs\n",
    "            inputs = batch[\"input_ids\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model.generate(inputs)\n",
    "            labels = torch.cat((torch.tensor([[0]]), labels), dim=1)\n",
    "            # Calculate accuracy\n",
    "            if outputs.shape == labels.shape:\n",
    "                correct_predictions = torch.equal(outputs, labels)\n",
    "            else:            \n",
    "                correct_predictions = False\n",
    "            total_correct += correct_predictions\n",
    "            total_samples += batch_size\n",
    "            # Log progress every log_interval steps\n",
    "            if (idx + 1) % log_interval == 0 or (idx + 1) == len(test_dataloader):\n",
    "                print(f\"Processed {idx+1}/{len(test_dataloader)} examples - Correct: {total_correct}\")\n",
    "    \n",
    "    print(\"Final Test Accuracy: {}%\".format(round(total_correct/total_samples * 100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your base model trained on the small training set of 100 english samples, reaches approximately **22% accuracy** (see below). Important: You do not need to execute the code again - This could run for a while.\n",
    "\n",
    "Let's see if we can improve on the task with cross-lingual transfer and transfer learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimye\\anaconda3\\envs\\Yevin\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/1000 examples - Correct: 3\n",
      "Processed 20/1000 examples - Correct: 7\n",
      "Processed 30/1000 examples - Correct: 11\n",
      "Processed 40/1000 examples - Correct: 12\n",
      "Processed 50/1000 examples - Correct: 16\n",
      "Processed 60/1000 examples - Correct: 18\n",
      "Processed 70/1000 examples - Correct: 24\n",
      "Processed 80/1000 examples - Correct: 30\n",
      "Processed 90/1000 examples - Correct: 35\n",
      "Processed 100/1000 examples - Correct: 38\n",
      "Processed 110/1000 examples - Correct: 43\n",
      "Processed 120/1000 examples - Correct: 47\n",
      "Processed 130/1000 examples - Correct: 49\n",
      "Processed 140/1000 examples - Correct: 51\n",
      "Processed 150/1000 examples - Correct: 54\n",
      "Processed 160/1000 examples - Correct: 57\n",
      "Processed 170/1000 examples - Correct: 60\n",
      "Processed 180/1000 examples - Correct: 65\n",
      "Processed 190/1000 examples - Correct: 69\n",
      "Processed 200/1000 examples - Correct: 73\n",
      "Processed 210/1000 examples - Correct: 78\n",
      "Processed 220/1000 examples - Correct: 81\n",
      "Processed 230/1000 examples - Correct: 85\n",
      "Processed 240/1000 examples - Correct: 90\n",
      "Processed 250/1000 examples - Correct: 93\n",
      "Processed 260/1000 examples - Correct: 93\n",
      "Processed 270/1000 examples - Correct: 97\n",
      "Processed 280/1000 examples - Correct: 102\n",
      "Processed 290/1000 examples - Correct: 105\n",
      "Processed 300/1000 examples - Correct: 110\n",
      "Processed 310/1000 examples - Correct: 113\n",
      "Processed 320/1000 examples - Correct: 116\n",
      "Processed 330/1000 examples - Correct: 121\n",
      "Processed 340/1000 examples - Correct: 125\n",
      "Processed 350/1000 examples - Correct: 128\n",
      "Processed 360/1000 examples - Correct: 132\n",
      "Processed 370/1000 examples - Correct: 137\n",
      "Processed 380/1000 examples - Correct: 139\n",
      "Processed 390/1000 examples - Correct: 141\n",
      "Processed 400/1000 examples - Correct: 144\n",
      "Processed 410/1000 examples - Correct: 148\n",
      "Processed 420/1000 examples - Correct: 153\n",
      "Processed 430/1000 examples - Correct: 155\n",
      "Processed 440/1000 examples - Correct: 160\n",
      "Processed 450/1000 examples - Correct: 162\n",
      "Processed 460/1000 examples - Correct: 166\n",
      "Processed 470/1000 examples - Correct: 169\n",
      "Processed 480/1000 examples - Correct: 170\n",
      "Processed 490/1000 examples - Correct: 173\n",
      "Processed 500/1000 examples - Correct: 179\n",
      "Processed 510/1000 examples - Correct: 186\n",
      "Processed 520/1000 examples - Correct: 189\n",
      "Processed 530/1000 examples - Correct: 191\n",
      "Processed 540/1000 examples - Correct: 193\n",
      "Processed 550/1000 examples - Correct: 197\n",
      "Processed 560/1000 examples - Correct: 200\n",
      "Processed 570/1000 examples - Correct: 207\n",
      "Processed 580/1000 examples - Correct: 211\n",
      "Processed 590/1000 examples - Correct: 215\n",
      "Processed 600/1000 examples - Correct: 217\n",
      "Processed 610/1000 examples - Correct: 221\n",
      "Processed 620/1000 examples - Correct: 224\n",
      "Processed 630/1000 examples - Correct: 229\n",
      "Processed 640/1000 examples - Correct: 231\n",
      "Processed 650/1000 examples - Correct: 235\n",
      "Processed 660/1000 examples - Correct: 238\n",
      "Processed 670/1000 examples - Correct: 242\n",
      "Processed 680/1000 examples - Correct: 246\n",
      "Processed 690/1000 examples - Correct: 247\n",
      "Processed 700/1000 examples - Correct: 249\n",
      "Processed 710/1000 examples - Correct: 252\n",
      "Processed 720/1000 examples - Correct: 255\n",
      "Processed 730/1000 examples - Correct: 259\n",
      "Processed 740/1000 examples - Correct: 262\n",
      "Processed 750/1000 examples - Correct: 266\n",
      "Processed 760/1000 examples - Correct: 271\n",
      "Processed 770/1000 examples - Correct: 275\n",
      "Processed 780/1000 examples - Correct: 279\n",
      "Processed 790/1000 examples - Correct: 283\n",
      "Processed 800/1000 examples - Correct: 284\n",
      "Processed 810/1000 examples - Correct: 288\n",
      "Processed 820/1000 examples - Correct: 294\n",
      "Processed 830/1000 examples - Correct: 296\n",
      "Processed 840/1000 examples - Correct: 301\n",
      "Processed 850/1000 examples - Correct: 303\n",
      "Processed 860/1000 examples - Correct: 307\n",
      "Processed 870/1000 examples - Correct: 311\n",
      "Processed 880/1000 examples - Correct: 313\n",
      "Processed 890/1000 examples - Correct: 318\n",
      "Processed 900/1000 examples - Correct: 322\n",
      "Processed 910/1000 examples - Correct: 324\n",
      "Processed 920/1000 examples - Correct: 328\n",
      "Processed 930/1000 examples - Correct: 332\n",
      "Processed 940/1000 examples - Correct: 337\n",
      "Processed 950/1000 examples - Correct: 338\n",
      "Processed 960/1000 examples - Correct: 343\n",
      "Processed 970/1000 examples - Correct: 345\n",
      "Processed 980/1000 examples - Correct: 348\n",
      "Processed 990/1000 examples - Correct: 353\n",
      "Processed 1000/1000 examples - Correct: 357\n",
      "Final Test Accuracy: 36%\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Train on our main task and test the model.\n",
    "training_inflection(model, train_data)\n",
    "test_accuracy(model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Lingual Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** Explain what cross-lingual transfer is (e.g. how it works, why it works). Explain how you would apply crosslingual transfer for our task (given the above datasets)? In which sitation do you think cross-lingual transfer will not work? (3P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": Cross-lingual transfer involves using knowledge acquired from a source language to upgrade the performance of a model on a different target language. The process entails pre-training the model on a sizable dataset in the source language to grasp general linguistic patterns. Then the pre-trained model undergoes fine-tuning on a smaller dataset in the target language for a specific task, adapting its parameters to the language's characteristics.\r\n",
    "\r\n",
    "\r\n",
    "train_file = os.path.join(data_dir, \"german-train-medium.txt\")\r\n",
    "crosslingual_train_data = read_conll_file(train_file)\r\n",
    "The code introduces German data from \"german-train-medium.txt\" into the main task's dataset (`crosslingual_train_data`). The pre-training model acquires general language characteristics from English data and adjusts to the German language during the fine-tuning process.The model is then trained on this combined dataset, constituting transfer learning with German language incorporation.\r\n",
    "\r\n",
    "\r\n",
    "Source-target language disparities, especially in structures, word orders, or grammatical rules, may impede effective pre-trained knowledge transfer. If the source and target languages are from different domains and the pre-training data doesn't adequately cover the target domain, effective transfer may be hindered; for instance, transferring knowledge from legal to medical text across vastly different domains may not be beneficial. Insufficient data quality or quantity in the target language, such as a small or noisy dataset, may hinder effective fine-tuning, impacting the cross-lingual transfer's effectiveness in capturing language-specific nuances.If the tasks between the source and target languages differ fundamentally, the success of cross-lingual transfer may be compromised, as it is most effective when tasks exhibit similrities.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:** Cross-Lingual Transfer: First train on the german dataset and then on the english dataset. Test the resulting model on the english test set. (2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 03:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.563900</td>\n",
       "      <td>2.185899</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.825400</td>\n",
       "      <td>2.205527</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.418800</td>\n",
       "      <td>2.272441</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/1000 examples - Correct: 4\n",
      "Processed 20/1000 examples - Correct: 10\n",
      "Processed 30/1000 examples - Correct: 15\n",
      "Processed 40/1000 examples - Correct: 16\n",
      "Processed 50/1000 examples - Correct: 22\n",
      "Processed 60/1000 examples - Correct: 25\n",
      "Processed 70/1000 examples - Correct: 31\n",
      "Processed 80/1000 examples - Correct: 37\n",
      "Processed 90/1000 examples - Correct: 44\n",
      "Processed 100/1000 examples - Correct: 49\n",
      "Processed 110/1000 examples - Correct: 52\n",
      "Processed 120/1000 examples - Correct: 58\n",
      "Processed 130/1000 examples - Correct: 61\n",
      "Processed 140/1000 examples - Correct: 65\n",
      "Processed 150/1000 examples - Correct: 70\n",
      "Processed 160/1000 examples - Correct: 73\n",
      "Processed 170/1000 examples - Correct: 76\n",
      "Processed 180/1000 examples - Correct: 80\n",
      "Processed 190/1000 examples - Correct: 85\n",
      "Processed 200/1000 examples - Correct: 91\n",
      "Processed 210/1000 examples - Correct: 95\n",
      "Processed 220/1000 examples - Correct: 98\n",
      "Processed 230/1000 examples - Correct: 103\n",
      "Processed 240/1000 examples - Correct: 109\n",
      "Processed 250/1000 examples - Correct: 113\n",
      "Processed 260/1000 examples - Correct: 117\n",
      "Processed 270/1000 examples - Correct: 124\n",
      "Processed 280/1000 examples - Correct: 129\n",
      "Processed 290/1000 examples - Correct: 131\n",
      "Processed 300/1000 examples - Correct: 137\n",
      "Processed 310/1000 examples - Correct: 143\n",
      "Processed 320/1000 examples - Correct: 147\n",
      "Processed 330/1000 examples - Correct: 155\n",
      "Processed 340/1000 examples - Correct: 160\n",
      "Processed 350/1000 examples - Correct: 163\n",
      "Processed 360/1000 examples - Correct: 168\n",
      "Processed 370/1000 examples - Correct: 174\n",
      "Processed 380/1000 examples - Correct: 177\n",
      "Processed 390/1000 examples - Correct: 180\n",
      "Processed 400/1000 examples - Correct: 184\n",
      "Processed 410/1000 examples - Correct: 187\n",
      "Processed 420/1000 examples - Correct: 193\n",
      "Processed 430/1000 examples - Correct: 197\n",
      "Processed 440/1000 examples - Correct: 202\n",
      "Processed 450/1000 examples - Correct: 204\n",
      "Processed 460/1000 examples - Correct: 209\n",
      "Processed 470/1000 examples - Correct: 212\n",
      "Processed 480/1000 examples - Correct: 214\n",
      "Processed 490/1000 examples - Correct: 220\n",
      "Processed 500/1000 examples - Correct: 226\n",
      "Processed 510/1000 examples - Correct: 233\n",
      "Processed 520/1000 examples - Correct: 238\n",
      "Processed 530/1000 examples - Correct: 242\n",
      "Processed 540/1000 examples - Correct: 244\n",
      "Processed 550/1000 examples - Correct: 251\n",
      "Processed 560/1000 examples - Correct: 254\n",
      "Processed 570/1000 examples - Correct: 262\n",
      "Processed 580/1000 examples - Correct: 268\n",
      "Processed 590/1000 examples - Correct: 272\n",
      "Processed 600/1000 examples - Correct: 275\n",
      "Processed 610/1000 examples - Correct: 278\n",
      "Processed 620/1000 examples - Correct: 285\n",
      "Processed 630/1000 examples - Correct: 291\n",
      "Processed 640/1000 examples - Correct: 294\n",
      "Processed 650/1000 examples - Correct: 297\n",
      "Processed 660/1000 examples - Correct: 303\n",
      "Processed 670/1000 examples - Correct: 307\n",
      "Processed 680/1000 examples - Correct: 314\n",
      "Processed 690/1000 examples - Correct: 316\n",
      "Processed 700/1000 examples - Correct: 318\n",
      "Processed 710/1000 examples - Correct: 323\n",
      "Processed 720/1000 examples - Correct: 325\n",
      "Processed 730/1000 examples - Correct: 329\n",
      "Processed 740/1000 examples - Correct: 335\n",
      "Processed 750/1000 examples - Correct: 337\n",
      "Processed 760/1000 examples - Correct: 342\n",
      "Processed 770/1000 examples - Correct: 348\n",
      "Processed 780/1000 examples - Correct: 351\n",
      "Processed 790/1000 examples - Correct: 357\n",
      "Processed 800/1000 examples - Correct: 360\n",
      "Processed 810/1000 examples - Correct: 363\n",
      "Processed 820/1000 examples - Correct: 369\n",
      "Processed 830/1000 examples - Correct: 373\n",
      "Processed 840/1000 examples - Correct: 379\n",
      "Processed 850/1000 examples - Correct: 386\n",
      "Processed 860/1000 examples - Correct: 390\n",
      "Processed 870/1000 examples - Correct: 398\n",
      "Processed 880/1000 examples - Correct: 404\n",
      "Processed 890/1000 examples - Correct: 407\n",
      "Processed 900/1000 examples - Correct: 413\n",
      "Processed 910/1000 examples - Correct: 416\n",
      "Processed 920/1000 examples - Correct: 420\n",
      "Processed 930/1000 examples - Correct: 425\n",
      "Processed 940/1000 examples - Correct: 429\n",
      "Processed 950/1000 examples - Correct: 431\n",
      "Processed 960/1000 examples - Correct: 439\n",
      "Processed 970/1000 examples - Correct: 442\n",
      "Processed 980/1000 examples - Correct: 447\n",
      "Processed 990/1000 examples - Correct: 453\n",
      "Processed 1000/1000 examples - Correct: 459\n",
      "Final Test Accuracy: 46%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "\"\"\"\n",
    "Your Code Here.\n",
    "\n",
    "Apply Cross-Lingual transfer with the given german dataset: \n",
    "Train the model on german dataset and then on the english one.\n",
    "\n",
    "Hint: Look at training_inflection() and test_accuracy()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Load the German dataset\n",
    "german_train_file = os.path.join(data_dir, \"german-train-medium.txt\")\n",
    "german_train_data = read_conll_file(german_train_file)\n",
    "\n",
    "# Train the model on the German dataset\n",
    "training_inflection(model, german_train_data)\n",
    "\n",
    "# Fine-tune on the English dataset\n",
    "training_inflection(model, train_data)\n",
    "\n",
    "# Test the resulting model on the English test set\n",
    "test_accuracy(model, test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: Explain your results! Argue why the performance \\[increased/decreased\\]. (2P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": The performance increased, and this can be attributed to the variance in the initial training data and fine-tuning data of the model.In the first model, it was trained directly on English training data and tested on English tasks. However, the second model was initially trained on German data. Subsequently, fine-tuning was performed using English data, illustrating an example of cross-lingual transfer.\r\n",
    "\r\n",
    "The effective application of cross-lingual transfer is evident in the increased accuracy. While the first model relied solely on English training, the second model leveraged the knowledge gained from German data during its initial training, demonstrating the ability to transfer learning across language\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try out Transfer Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:** Explain what Transfer Learning and multi-task learning is (e.g. how it works, why it works). What is the difference? (3P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": Tansfer learning entails improving a model's performance on a related task by utilizing knowledge gained from training on a different task. Specifically in natural language processing, this involves pre-training on a language modeling task, followed by fine-tuning for a specific downstream task, leveraging general linguistic features and proving advantageous when labeled data for the target task is scarce.Multi-task learning concurrently trains a model on various tasks, aiming to leverage shared knowledge for improved overall performance. In NLP, this can encompass training on diverse language-related tasks, such as part-of-speech tagging and sentiment analysis. Transfer learning improves a model's performance on a related task by leveraging knowledge from training on a different task, while multi-task learning simultaneously trains a model on various tasks to enhance overall performance, particularly in NLP with diverse language-related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning: First, we train on a \"utility\" task (source task) and then fine-tune on our main task (target task), which is the inflection task.\n",
    "\n",
    "Now, imagine I give you a dataset with only the base word (lemma) and its changed form (inflected form), but without the morphological features, e.g. \"Reflektion\" and \"Reflektionen\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5**: What kind of source task could you create to help with our target task (excluding my proposed task underneath)? Explain your decision! (2P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": Source task thatinvolves training the model in \"Syntactic Dependency Parsing\" or \"Semantic Role Labeling.\" could help with our target task. These tasks focus on understanding grammatical relationships and semantic roles within sentences, providing valuable linguistic insights. Syntactic Dependency Parsing teaches the model about sentence structures, while Semantic Role Labeling enhances its understanding of the semantic roles each word plays. Incorporating these tasks can deepen the model's comprehension of language features not explicitly covered in the existing code, ultimately improving its performance in the target task of inflection generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it interesting by mimicking T5's pre-training (so you also learn how T5 pre-trains).\n",
    "\n",
    "We'll randomly mask some characters where the input will be the base word and its inflected form:, for example, turning _\"Reflektion Reflektionen\" -> \"Refle\\<masked1\\>tion Refletion\\<masked2\\>\"_. The task is to predict the missing characters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll show you how T5 expects its input format. You can also check it out here: https://huggingface.co/docs/transformers/model_doc/t5#training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  419,    89,    40, 32099,     3,    17,    23,    32, 32098,     1]])\n",
      "tensor([[32099,     3,    15,   157, 32098,     3,    29, 32097,     1]])\n"
     ]
    }
   ],
   "source": [
    "# From Huggingface: \n",
    "# In this setup, spans of the input sequence are masked by so-called sentinel tokens (a.k.a unique mask tokens) \n",
    "# and the output sequence is formed as a concatenation of the same sentinel tokens and the real masked tokens. \n",
    "# Each sentinel token represents a unique mask token for this sentence and should start with \n",
    "# <extra_id_0>, <extra_id_1>, â€¦ up to <extra_id_99>.\n",
    "\n",
    "input_ids = tokenizer(\"Refl<extra_id_0>tio<extra_id_1>\", return_tensors=\"pt\").input_ids\n",
    "print(input_ids)\n",
    "\n",
    "label_ids = tokenizer(\"<extra_id_0>ek<extra_id_1>n<extra_id_2>\", return_tensors=\"pt\").input_ids\n",
    "print(label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5 uses up to 100 \"sentinal tokens\", i.e. masking tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>']\n"
     ]
    }
   ],
   "source": [
    "num_extra_tokens = 100\n",
    "special_tokens = [f\"<extra_id_{i}>\" for i in range(num_extra_tokens)]\n",
    "\n",
    "print(special_tokens[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6:** Explain whether this task could be beneficial for the main task or not! (2P)\n",
    "\n",
    "_Feel free to present arguments against this task. I was exploring tasks that might be relevant and found this one interesting :)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this task might be less beneficial than a cross-lingual transfer. The utility task and the inflection task are significantly different. If the source task doesn't provide relevant information or features for the target task, transfer learning may not be beneficial. The original approach involves fine-tuning the model on German data and then further fine-tuning it on English data. However, in this case, we randomly mask some characters in tokenized input. This random masking can make it difficult for the model to predict specific positions accurately, especially when there is a lack of context. Therefore, it can be said that this approach is not beneficial, particularly due to the challenges posed by insufficient context for accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7:** Create the dataset for the above task! (3P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set a specific seed value\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "def dropout_and_replace(word, dropout_prob=0.3, sentinel_tokens=special_tokens):\n",
    "    \"\"\"\n",
    "    Dropout characters in a word based on the given probability and replace them with sentinel tokens.\n",
    "\n",
    "    Parameters:\n",
    "    - word (str): The input word.\n",
    "    - dropout_prob (float): The probability of dropping out each character.\n",
    "    - sentinel_tokens (list): List of sentinel tokens to replace dropped characters.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified word with dropout and replacement.\n",
    "    \"\"\"\n",
    "    masked_word = \"\"\n",
    "    label = \"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Your Code Here.\n",
    "    \n",
    "    \"\"\"\n",
    "    for char in word:\n",
    "        # Randomly decide whether to drop out the character\n",
    "        if random.uniform(0, 1) < dropout_prob:\n",
    "            # Drop out the character and replace with a sentinel token\n",
    "            masked_word += random.choice(sentinel_tokens)\n",
    "            label += char\n",
    "        else:\n",
    "            masked_word += char\n",
    "            label += f\"<extra_id_{random.randint(0, num_extra_tokens - 1)}>\"\n",
    "\n",
    "    return masked_word, label\n",
    "\n",
    "def transferlearning_token_ids(data, tokenizer, dropout_prob=0.3, special_tokens=special_tokens):\n",
    "    # Use this dictionary to collect your data\n",
    "    tokenized = {\n",
    "        \"input_ids\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "\n",
    "    # Loop through raw data to tokenize and create training data\n",
    "    for example in data:\n",
    "        \"\"\"\n",
    "        Your Code Here\n",
    "\n",
    "        Remember that the input should be lemma + \" \" + inflected_form.\n",
    "        \"\"\"\n",
    "        # Concatenate the lemma and inflected_form with a space\n",
    "        input_text = example[0] + \" \" + example[1]\n",
    "\n",
    "        # Apply dropout_and_replace to create the masked input and labels\n",
    "        masked_input, label = dropout_and_replace(input_text, dropout_prob, special_tokens)\n",
    "\n",
    "        # Tokenize the masked input and labels\n",
    "        tokens = tokenizer(masked_input, return_tensors='pt')\n",
    "        label_tokens = tokenizer(label, return_tensors='pt')\n",
    "\n",
    "        input_ids = tokens['input_ids'].squeeze()\n",
    "        label_ids = label_tokens['input_ids'].squeeze()\n",
    "\n",
    "        # Append to the PyTorch dictionary\n",
    "        tokenized['input_ids'].append(input_ids)\n",
    "        tokenized['label'].append(label_ids)\n",
    "\n",
    "    # This code shuffles the data!\n",
    "    combined_lists = list(zip(tokenized['input_ids'], tokenized['label']))\n",
    "    # Shuffle the combined pairs\n",
    "    random.shuffle(combined_lists)\n",
    "    tokenized['input_ids'], tokenized['label'] = zip(*combined_lists)\n",
    "\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m dropout_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m      9\u001b[0m input_word, label_word \u001b[38;5;241m=\u001b[39m dropout_and_replace(word, dropout_prob, special_tokens)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m input_word \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR<extra_id_0>ekt<extra_id_1>o<extra_id_2>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m label_word \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<extra_id_0>efl<extra_id_1>i<extra_id_2>n<extra_id_3>\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This assert will only work if you initialize dropout_and_replace() without calling it first!\n",
    "# Depending on your function implementation this might not work anyways\n",
    "# But this should give you a good hint of the dropout_and_replace() function\n",
    "\n",
    "# Testing with one word\n",
    "# Example usage:\n",
    "word = \"Reflektion\"\n",
    "dropout_prob = 0.3\n",
    "input_word, label_word = dropout_and_replace(word, dropout_prob, special_tokens)\n",
    "\n",
    "assert input_word == 'R<extra_id_0>ekt<extra_id_1>o<extra_id_2>'\n",
    "assert label_word == '<extra_id_0>efl<extra_id_1>i<extra_id_2>n<extra_id_3>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransferLearningDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.tokenized_data = tokenized_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.tokenized_data[\"input_ids\"][idx],\n",
    "            \"labels\": self.tokenized_data[\"label\"][idx]\n",
    "        }\n",
    "\n",
    "# Create the PyTorch dataset\n",
    "train_tokenized = transferlearning_token_ids(transferlearning_train_data, tokenizer)\n",
    "train_dataset = TransferLearningDataset(train_tokenized)\n",
    "\n",
    "dev_tokenized = transferlearning_token_ids(dev_data, tokenizer)\n",
    "dev_dataset = TransferLearningDataset(dev_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8:** Now train the model on our source task and then on our target task. Test the resulting model! Did the performance increase? Why or why not? (3P)\n",
    "\n",
    "_Hint: Use Seq2SeqTrainingArguments, Seq2SeqTrainer with a learning rate of 5e-4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Settings\n",
    "learning_rate, per_device_train_batch_size, num_train_epochs = 5e-4, 16, 5\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(preds):\n",
    "    output, labels = preds\n",
    "    predictions = torch.argmax(torch.tensor(output[0]), dim=-1)\n",
    "    predictions = torch.where(labels != -100, predictions, torch.tensor(0))\n",
    "    labels = torch.where(labels != -100, labels, torch.tensor(0))\n",
    "    accuracy = torch.mean(torch.all(predictions == labels, dim=1).float())\n",
    "    return {\"accuracy\": accuracy.item()}\n",
    "\n",
    "# Custom PyTorch dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.tokenized_data = tokenized_data\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data[\"input_ids\"])\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"input_ids\": self.tokenized_data[\"input_ids\"][idx], \"labels\": self.tokenized_data[\"label\"][idx]}\n",
    "\n",
    "# Tokenizer and Model Initialization\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Function to transform data to token IDs\n",
    "def transform_to_token_ids(data):\n",
    "    return {\"input_ids\": [tokenizer(x[0] + \" \" + x[2], return_tensors='pt')['input_ids'].squeeze() for x in data],\n",
    "            \"label\": [tokenizer(x[1], return_tensors='pt')['input_ids'].squeeze() for x in data]}\n",
    "\n",
    "# Training function\n",
    "def training_inflection(model, train_data, dev_data=None, learning_rate=5e-4):\n",
    "    train_dataset = CustomDataset(transform_to_token_ids(train_data))\n",
    "    dev_dataset = CustomDataset(transform_to_token_ids(dev_data)) if dev_data else None\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"./output\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=1,\n",
    "        num_train_epochs=3,\n",
    "        logging_steps=60,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=60,\n",
    "        learning_rate=learning_rate,\n",
    "    )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "# Training on the source task\n",
    "training_inflection(model, train_data, dev_data=dev_data, learning_rate=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/1000 examples - Correct: 3\n",
      "Processed 20/1000 examples - Correct: 7\n",
      "Processed 30/1000 examples - Correct: 11\n",
      "Processed 40/1000 examples - Correct: 12\n",
      "Processed 50/1000 examples - Correct: 17\n",
      "Processed 60/1000 examples - Correct: 19\n",
      "Processed 70/1000 examples - Correct: 25\n",
      "Processed 80/1000 examples - Correct: 29\n",
      "Processed 90/1000 examples - Correct: 32\n",
      "Processed 100/1000 examples - Correct: 35\n",
      "Processed 110/1000 examples - Correct: 36\n",
      "Processed 120/1000 examples - Correct: 40\n",
      "Processed 130/1000 examples - Correct: 42\n",
      "Processed 140/1000 examples - Correct: 45\n",
      "Processed 150/1000 examples - Correct: 48\n",
      "Processed 160/1000 examples - Correct: 50\n",
      "Processed 170/1000 examples - Correct: 53\n",
      "Processed 180/1000 examples - Correct: 55\n",
      "Processed 190/1000 examples - Correct: 58\n",
      "Processed 200/1000 examples - Correct: 62\n",
      "Processed 210/1000 examples - Correct: 67\n",
      "Processed 220/1000 examples - Correct: 69\n",
      "Processed 230/1000 examples - Correct: 73\n",
      "Processed 240/1000 examples - Correct: 77\n",
      "Processed 250/1000 examples - Correct: 80\n",
      "Processed 260/1000 examples - Correct: 81\n",
      "Processed 270/1000 examples - Correct: 88\n",
      "Processed 280/1000 examples - Correct: 92\n",
      "Processed 290/1000 examples - Correct: 94\n",
      "Processed 300/1000 examples - Correct: 100\n",
      "Processed 310/1000 examples - Correct: 102\n",
      "Processed 320/1000 examples - Correct: 106\n",
      "Processed 330/1000 examples - Correct: 110\n",
      "Processed 340/1000 examples - Correct: 114\n",
      "Processed 350/1000 examples - Correct: 117\n",
      "Processed 360/1000 examples - Correct: 117\n",
      "Processed 370/1000 examples - Correct: 122\n",
      "Processed 380/1000 examples - Correct: 124\n",
      "Processed 390/1000 examples - Correct: 127\n",
      "Processed 400/1000 examples - Correct: 130\n",
      "Processed 410/1000 examples - Correct: 132\n",
      "Processed 420/1000 examples - Correct: 135\n",
      "Processed 430/1000 examples - Correct: 138\n",
      "Processed 440/1000 examples - Correct: 141\n",
      "Processed 450/1000 examples - Correct: 142\n",
      "Processed 460/1000 examples - Correct: 143\n",
      "Processed 470/1000 examples - Correct: 145\n",
      "Processed 480/1000 examples - Correct: 146\n",
      "Processed 490/1000 examples - Correct: 151\n",
      "Processed 500/1000 examples - Correct: 155\n",
      "Processed 510/1000 examples - Correct: 162\n",
      "Processed 520/1000 examples - Correct: 163\n",
      "Processed 530/1000 examples - Correct: 165\n",
      "Processed 540/1000 examples - Correct: 167\n",
      "Processed 550/1000 examples - Correct: 172\n",
      "Processed 560/1000 examples - Correct: 174\n",
      "Processed 570/1000 examples - Correct: 179\n",
      "Processed 580/1000 examples - Correct: 185\n",
      "Processed 590/1000 examples - Correct: 190\n",
      "Processed 600/1000 examples - Correct: 191\n",
      "Processed 610/1000 examples - Correct: 195\n",
      "Processed 620/1000 examples - Correct: 197\n",
      "Processed 630/1000 examples - Correct: 201\n",
      "Processed 640/1000 examples - Correct: 203\n",
      "Processed 650/1000 examples - Correct: 206\n",
      "Processed 660/1000 examples - Correct: 211\n",
      "Processed 670/1000 examples - Correct: 214\n",
      "Processed 680/1000 examples - Correct: 217\n",
      "Processed 690/1000 examples - Correct: 218\n",
      "Processed 700/1000 examples - Correct: 218\n",
      "Processed 710/1000 examples - Correct: 222\n",
      "Processed 720/1000 examples - Correct: 225\n",
      "Processed 730/1000 examples - Correct: 228\n",
      "Processed 740/1000 examples - Correct: 231\n",
      "Processed 750/1000 examples - Correct: 233\n",
      "Processed 760/1000 examples - Correct: 235\n",
      "Processed 770/1000 examples - Correct: 239\n",
      "Processed 780/1000 examples - Correct: 243\n",
      "Processed 790/1000 examples - Correct: 246\n",
      "Processed 800/1000 examples - Correct: 248\n",
      "Processed 810/1000 examples - Correct: 252\n",
      "Processed 820/1000 examples - Correct: 257\n",
      "Processed 830/1000 examples - Correct: 259\n",
      "Processed 840/1000 examples - Correct: 263\n",
      "Processed 850/1000 examples - Correct: 267\n",
      "Processed 860/1000 examples - Correct: 270\n",
      "Processed 870/1000 examples - Correct: 272\n",
      "Processed 880/1000 examples - Correct: 274\n",
      "Processed 890/1000 examples - Correct: 278\n",
      "Processed 900/1000 examples - Correct: 282\n",
      "Processed 910/1000 examples - Correct: 283\n",
      "Processed 920/1000 examples - Correct: 286\n",
      "Processed 930/1000 examples - Correct: 288\n",
      "Processed 940/1000 examples - Correct: 291\n",
      "Processed 950/1000 examples - Correct: 292\n",
      "Processed 960/1000 examples - Correct: 295\n",
      "Processed 970/1000 examples - Correct: 297\n",
      "Processed 980/1000 examples - Correct: 300\n",
      "Processed 990/1000 examples - Correct: 303\n",
      "Processed 1000/1000 examples - Correct: 307\n",
      "Final Test Accuracy: 31%\n"
     ]
    }
   ],
   "source": [
    "# Then train on our main task and test the model.\n",
    "\n",
    "training_inflection(model, train_data)\n",
    "test_accuracy(model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": As discussed in task 6, this approach did not seem to work well for the target inflection task. It was less accurate than cross-lingual transfer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

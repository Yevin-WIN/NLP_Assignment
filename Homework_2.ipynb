{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 2: Word Embeddings\n",
    "#### Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Yevin Kim, kimyevin17@gmail.com*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this homework we're going to be looking at word embeddings and their properties.\n",
    "\n",
    "*Total Points: 20P*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Free Response Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: Describe the word similarity evaluation task! (1P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    ": Word similarity is a numerical representation of the similarity between two words. The more similar or interchangeable the words, the higher the similarity, and the less similar the words with different meanings. It is one of the methods to evaluate embedding Model that allows to check the accuracy of the embedding process of turning natural language into vector form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: Describe the word analogy evaluation task! (1P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    ": Word analogy is also a means of evaluating embedding models. However, word analogy aims to look at pairs of words that are in a similar relationship, find words that are in the same relationship, and determine if there is a grammatical or semantic relationship between the words. For example, a gender relationship or a parent word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Word Similarity Evaluation\n",
    "\n",
    "In this section, we will follow part of: https://aclanthology.org/Q15-1016.pdf\n",
    "\n",
    "1. We'll first load the GloVe embeddings. You can download the embeddings from here: https://nlp.stanford.edu/projects/glove/.\n",
    "Download the 6B version and get the 50d dimension embedding. If this link is too slow (or too big), you can also try to google and directly get the 6B, 50d version.\n",
    "\n",
    "2. Download the Word Embedding Similarity dataset here: http://alfonseca.org/eng/research/wordsim353.html. Unpack the file here.\n",
    "\n",
    "Put both files (*glove.6B.50d.txt and wordsim_similarity_goldstandard.txt*) in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Word Similarity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your dataset file\n",
    "file_path = \"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Open the file and read its contents line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line into a list of values using tab as the delimiter\n",
    "        values = line.strip().split('\\t')\n",
    "        data.append(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Describe the structure of the dataset. (1P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    ": A structure that lists word pairs of two words and the similarity between them. The delimiter for each line is '\\t'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the GloVe embeddings from the text file that you just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words from glove\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "glove_file = 'glove.6B.50d.txt'\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip().split(' ')\n",
    "        word = line[0]\n",
    "        embed = numpy.asarray(line[1:], \"float\")\n",
    "        embeddings_dict[word] = embed\n",
    "\n",
    "print('Loaded {} words from glove'.format(len(embeddings_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Describe the structure of embeddings_dict (1P). Then get the embedding for the word 'vietnam'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    ": Each line of the dataset has a set of values separated by 'spaces'. The first part of the line is the corresponding natural language word, and the rest is the vector representations of the word. In this case, embeddings_dict[word] uses the corresponding lexeme as the key and the word's embedding (vector representations) as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for \"vietnam\": [ 0.015116  -0.10943   -0.27907    0.21508   -0.29031   -0.53296\n",
      "  0.19078   -0.41052    0.44114   -0.62994    0.18833   -0.21939\n",
      "  0.41152   -0.50776    0.43244   -0.53374   -0.64635    0.71545\n",
      "  0.32507    1.2133    -0.28625   -0.70367    0.3289    -0.75187\n",
      "  0.36866   -1.91      -0.045114  -0.29222   -0.13062   -0.085536\n",
      "  2.4892     0.38918   -0.20016    0.6271    -0.70908    0.065848\n",
      " -0.6934     0.42858   -0.96318    0.21551   -1.26       0.10016\n",
      "  0.88836   -1.2289     0.66346   -0.34112   -0.59078    0.12597\n",
      " -0.30163    0.0054462]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your Code here. (1P)\n",
    "\n",
    "Get the embedding for the word 'vietnam'.\n",
    "\n",
    "'''\n",
    "\n",
    "target_word = 'vietnam'\n",
    "if target_word in embeddings_dict:\n",
    "    embedding = embeddings_dict[target_word]\n",
    "    print(f'Embedding for \"{target_word}\": {embedding}')\n",
    "else:\n",
    "    print(f'Embedding for \"{target_word}\" is not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we downloaded our dataset and word embeddings, we can calculate the word similarities for each word pair in the dataset.\n",
    "\n",
    "We first calculate the similarity based on the cosine similarity!\n",
    "\n",
    "Cosine similarity is defined as:\n",
    "\n",
    "**1 - cosine_distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 'tiger' and 'cat', Cosine Similarity: 0.6150732418405163, Ground Truth: 7.35\n",
      "Words: 'tiger' and 'tiger', Cosine Similarity: 1.0, Ground Truth: 10.00\n",
      "Words: 'plane' and 'car', Cosine Similarity: 0.6656114206912428, Ground Truth: 5.77\n",
      "Words: 'train' and 'car', Cosine Similarity: 0.7658227528614755, Ground Truth: 6.31\n",
      "Words: 'television' and 'radio', Cosine Similarity: 0.8709275278715247, Ground Truth: 6.77\n",
      "Words: 'media' and 'radio', Cosine Similarity: 0.7614966025988953, Ground Truth: 7.42\n",
      "Words: 'bread' and 'butter', Cosine Similarity: 0.84021999893445, Ground Truth: 6.19\n",
      "Words: 'cucumber' and 'potato', Cosine Similarity: 0.7118516503650524, Ground Truth: 5.92\n",
      "Words: 'doctor' and 'nurse', Cosine Similarity: 0.7977497347874546, Ground Truth: 7.00\n",
      "Words: 'professor' and 'doctor', Cosine Similarity: 0.5824731746059034, Ground Truth: 6.62\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your Code here. (3P)\n",
    "\n",
    "Calculate the cosine similarity for each pair in the dataset. \n",
    "Ignore a word pair, if one of the words are not in the embedding dictionary (Out-of-Vocabulary case).\n",
    "Print out the first 10 word pairs with their corresponding cosine similarity and ground truth, e.g.\n",
    "\n",
    "Words: 'tiger' and 'cat', Cosine Similarity: 0.6150732418405161, Ground Truth: 7.35\n",
    "Words: 'tiger' and 'tiger', Cosine Similarity: 1.0, Ground Truth: 10.00\n",
    "Words: 'plane' and 'car', Cosine Similarity: 0.6656114206912427, Ground Truth: 5.77\n",
    "Words: 'train' and 'car', Cosine Similarity: 0.7658227528614756, Ground Truth: 6.31\n",
    "Words: 'television' and 'radio', Cosine Similarity: 0.8709275278715244, Ground Truth: 6.77\n",
    "...\n",
    "\n",
    "'''\n",
    "\n",
    "cosine_similarities = [] # Save all (valid = Not Out-of-Vocabulary case) cosine similarities\n",
    "ground_truth_similarities_valid = [] # Save all (valid = Not Out-of-Vocabulary case) ground truth similarities\n",
    "\n",
    "# Define Cosine Similarity function based on Numpy\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B) / (norm(A) * norm(B))\n",
    "    \n",
    "# Calculate cosine similarity for each pair of words in the dataset\n",
    "for pair in data:\n",
    "    word1, word2, ground_truth = pair[0], pair[1], float(pair[2])\n",
    "\n",
    "    # Check word1, word2 are in the embedding dictionary\n",
    "    if word1 in embeddings_dict and word2 in embeddings_dict:\n",
    "        vec1 = embeddings_dict[word1]\n",
    "        vec2 = embeddings_dict[word2]\n",
    "\n",
    "        # Calcutate cosine similarity\n",
    "        similarity = cos_sim(vec1, vec2)\n",
    "\n",
    "        # Append to List\n",
    "        cosine_similarities.append(similarity)\n",
    "        ground_truth_similarities_valid.append(ground_truth)\n",
    "\n",
    "# Print out the first 10 word pairs with their corresponding cosine similarity and gold standard\n",
    "for i in range(10):\n",
    "    word1 = data[i][0]\n",
    "    word2 = data[i][1]\n",
    "    similarity = cosine_similarities[i]\n",
    "    ground_truth = ground_truth_similarities_valid[i]\n",
    "    print(f\"Words: '{word1}' and '{word2}', Cosine Similarity: {similarity}, Ground Truth: {ground_truth:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same, but this time, we calculate the euclidean distance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 'tiger' and 'cat', Euclidean Distance: 4.122908683917116, Cosine Similarity: 0.6150732418405163, Ground Truth: 7.35\n",
      "Words: 'tiger' and 'tiger', Euclidean Distance: 0.0, Cosine Similarity: 1.0, Ground Truth: 10.00\n",
      "Words: 'plane' and 'car', Euclidean Distance: 4.709723268968757, Cosine Similarity: 0.6656114206912428, Ground Truth: 5.77\n",
      "Words: 'train' and 'car', Euclidean Distance: 3.7620738285880053, Cosine Similarity: 0.7658227528614755, Ground Truth: 6.31\n",
      "Words: 'television' and 'radio', Euclidean Distance: 2.9268013566606483, Cosine Similarity: 0.8709275278715247, Ground Truth: 6.77\n",
      "Words: 'media' and 'radio', Euclidean Distance: 3.822406423714884, Cosine Similarity: 0.7614966025988953, Ground Truth: 7.42\n",
      "Words: 'bread' and 'butter', Euclidean Distance: 3.308872389435863, Cosine Similarity: 0.84021999893445, Ground Truth: 6.19\n",
      "Words: 'cucumber' and 'potato', Euclidean Distance: 3.8450463825822703, Cosine Similarity: 0.7118516503650524, Ground Truth: 5.92\n",
      "Words: 'doctor' and 'nurse', Euclidean Distance: 3.1274530258887405, Cosine Similarity: 0.7977497347874546, Ground Truth: 7.00\n",
      "Words: 'professor' and 'doctor', Euclidean Distance: 5.014531842250995, Cosine Similarity: 0.5824731746059034, Ground Truth: 6.62\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your Code here. (2P)\n",
    "\n",
    "Calculate the euclidean distance for each pair in the dataset. \n",
    "Ignore a word pair, if one of the words are not in the embedding dictionary (Out-of-Vocabulary case).\n",
    "Print out the first 10 word pairs with their corresponding cosine similarity and ground truth\n",
    "\n",
    "'''\n",
    "euclidean_distances = [] # Save all (valid = Not Out-of-Vocabulary case) euclidean distances\n",
    "ground_truth_similarities_valid = [] # Save all (valid = Not Out-of-Vocabulary case) ground truth similarities\n",
    "\n",
    "# Define a function to calculate Euclidean distance based on numpy\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_dis(A, B):\n",
    "    return np.sqrt(np.sum((A-B)**2))\n",
    "\n",
    "# Calculate Euclidean distances for each pair of words in the dataset\n",
    "for pair in data:\n",
    "    word1, word2, ground_truth = pair[0], pair[1], float(pair[2])\n",
    "\n",
    "    # Check word1, word2 are in the embedding dictionary\n",
    "    if word1 in embeddings_dict and word2 in embeddings_dict:\n",
    "        vec1 = embeddings_dict[word1]\n",
    "        vec2 = embeddings_dict[word2]\n",
    "\n",
    "        # Calcutate cosine similarity\n",
    "        distance = euclidean_dis(vec1, vec2)\n",
    "\n",
    "        # Append to List\n",
    "        euclidean_distances.append(distance)\n",
    "        ground_truth_similarities_valid.append(ground_truth)\n",
    "\n",
    "\n",
    "# Display the computed Euclidean distances for the first 10 samples\n",
    "for i in range(10):\n",
    "    word1 = data[i][0]\n",
    "    word2 = data[i][1]\n",
    "    distance = euclidean_distances[i]\n",
    "    similarity = cosine_similarities[i]\n",
    "    ground_truth = ground_truth_similarities_valid[i]\n",
    "    print(f\"Words: '{word1}' and '{word2}', Euclidean Distance: {distance}, Cosine Similarity: {similarity}, Ground Truth: {ground_truth:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate: Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we calculated our predictions, how well does this correlate to the ground truth? We use the pearson coefficient for evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient for Cosine Similarity: 0.5417623796761136\n",
      "Pearson Correlation Coefficient for Euclidean Distance: -0.5748440058552572\n",
      "Euclidean Distance is a better predictor.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your Code here. (2P)\n",
    "\n",
    "Calculate the pearson correlation coefficient for the cosine similarity and euclidean distance to the ground truth.\n",
    "You are allowed to use the numpy implementation of pearson coefficient.\n",
    "Print out both metric scores.\n",
    "Which predictions are better, cosine similarity and euclidean distance? \n",
    "Take into account that one is measuring the similarity and the other distance!\n",
    "\n",
    "'''\n",
    "# Calculate the Pearson correlation coefficient for cosine similarity and ground truth\n",
    "corr_cos_sim = np.corrcoef(cosine_similarities, ground_truth_similarities_valid)[0, 1]\n",
    "\n",
    "# Calculate the Pearson correlation coefficient for Euclidean distance and ground truth\n",
    "corr_euclidean_dis = np.corrcoef(euclidean_distances, ground_truth_similarities_valid)[0, 1]\n",
    "\n",
    "# Print out the correlation coefficients\n",
    "print(f\"Pearson Correlation Coefficient for Cosine Similarity: {corr_cos_sim}\")\n",
    "print(f\"Pearson Correlation Coefficient for Euclidean Distance: {corr_euclidean_dis}\")\n",
    "\n",
    "# Result: which is better?\n",
    "if abs(corr_cos_sim) > abs(corr_euclidean_dis):\n",
    "    print(\"Cosine Similarity is a better predictor.\")\n",
    "else:\n",
    "    print(\"Euclidean Distance is a better predictor.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Word Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we begin with our second evaluation task: Word Analogy! Download the dataset here http://www.fit.vutbr.cz/~imikolov/rnnlm/word-test.v1.txt, and unpack it in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy 1: Athens Greece Baghdad Iraq\n",
      "Analogy 2: Baghdad Iraq Stockholm Sweden\n",
      "Analogy 3: Beijing China Paris France\n",
      "Analogy 4: Bern Switzerland Oslo Norway\n",
      "Analogy 5: Canberra Australia Madrid Spain\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the word analogy file\n",
    "file_path = \"word-test.v1.txt\"\n",
    "\n",
    "# Initialize a list to store the analogies\n",
    "analogies = []\n",
    "\n",
    "# Open the file and read its contents line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    analogy = []\n",
    "    for line_number, line in enumerate(file):\n",
    "        if line_number == 0: \n",
    "            continue  # Skip the first line\n",
    "        line = line.strip()\n",
    "        if line.startswith(\":\"):\n",
    "            if analogy:\n",
    "                analogies.append(analogy)  \n",
    "            analogy = [line]\n",
    "        else:\n",
    "            analogy.append(line)\n",
    "\n",
    "\n",
    "# Get all GT words\n",
    "GT_WORDS = []\n",
    "for analogy in analogies[0] +  analogies[4]:\n",
    "    if not analogy.startswith(\":\"):  # Skip lines starting with \":\"\n",
    "        GT_WORDS.extend(analogy.lower().split())\n",
    "GT_WORDS = list(set(GT_WORDS))\n",
    "\n",
    "# Only keep country & family analogy and reduce number of examples\n",
    "analogies = analogies[0][1::40] +  analogies[4][1::40]\n",
    "\n",
    "\n",
    "# Display the first few analogies\n",
    "for i, analogy in enumerate(analogies[:5]):  # Display the first 5 analogies for example\n",
    "    print(f\"Analogy {i + 1}: {analogy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Explain the dataset's structure (stored as analogies), and how you would use this dataset to evaluate your word embeddings. (2P)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    ": The \"analogies\" configuration stores word-to-word relationships, specifically related to capital-country and family arrangements, by the given code.\n",
    " The \"analogies\" array comprises four-word groupings, as evidenced by the code output below. The method for evaluating this word embedding involves computing the vector relation between the first two words, and subsequently measuring the precision with which the fourth word, connected in a similar manner whilst inserting the third word, can be derived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the projection with the first three words of each sample. The last word is the ground truth of the analogy task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection 1: [ 0.071815   1.04173   -0.53635   -0.46468    1.26138    0.98833\n",
      " -0.68096    0.4872    -0.71339   -0.21135    0.02327    0.584147\n",
      " -0.19358   -1.20716    1.261404  -0.28098   -1.09004    0.05105\n",
      "  0.36973    1.24253   -0.52907    1.45411   -0.16751    0.1921073\n",
      "  0.912203  -2.38913   -0.17003   -0.80068   -0.24877    0.07134\n",
      "  1.81577   -0.22733   -0.540853   0.88672    0.98941   -0.037356\n",
      "  0.10904   -0.03734    0.84183   -0.42766   -0.477841   0.48637\n",
      " -0.19205   -0.60838    0.30147   -0.90495   -0.60697   -1.8407\n",
      "  0.837017   0.108032 ]\n",
      "Projection 2: [ 0.071815   1.04173   -0.53635   -0.46468    1.26138    0.98833\n",
      " -0.68096    0.4872    -0.71339   -0.21135    0.02327    0.584147\n",
      " -0.19358   -1.20716    1.261404  -0.28098   -1.09004    0.05105\n",
      "  0.36973    1.24253   -0.52907    1.45411   -0.16751    0.1921073\n",
      "  0.912203  -2.38913   -0.17003   -0.80068   -0.24877    0.07134\n",
      "  1.81577   -0.22733   -0.540853   0.88672    0.98941   -0.037356\n",
      "  0.10904   -0.03734    0.84183   -0.42766   -0.477841   0.48637\n",
      " -0.19205   -0.60838    0.30147   -0.90495   -0.60697   -1.8407\n",
      "  0.837017   0.108032 ]\n",
      "Projection 3: [ 0.071815   1.04173   -0.53635   -0.46468    1.26138    0.98833\n",
      " -0.68096    0.4872    -0.71339   -0.21135    0.02327    0.584147\n",
      " -0.19358   -1.20716    1.261404  -0.28098   -1.09004    0.05105\n",
      "  0.36973    1.24253   -0.52907    1.45411   -0.16751    0.1921073\n",
      "  0.912203  -2.38913   -0.17003   -0.80068   -0.24877    0.07134\n",
      "  1.81577   -0.22733   -0.540853   0.88672    0.98941   -0.037356\n",
      "  0.10904   -0.03734    0.84183   -0.42766   -0.477841   0.48637\n",
      " -0.19205   -0.60838    0.30147   -0.90495   -0.60697   -1.8407\n",
      "  0.837017   0.108032 ]\n",
      "Projection 4: [ 0.071815   1.04173   -0.53635   -0.46468    1.26138    0.98833\n",
      " -0.68096    0.4872    -0.71339   -0.21135    0.02327    0.584147\n",
      " -0.19358   -1.20716    1.261404  -0.28098   -1.09004    0.05105\n",
      "  0.36973    1.24253   -0.52907    1.45411   -0.16751    0.1921073\n",
      "  0.912203  -2.38913   -0.17003   -0.80068   -0.24877    0.07134\n",
      "  1.81577   -0.22733   -0.540853   0.88672    0.98941   -0.037356\n",
      "  0.10904   -0.03734    0.84183   -0.42766   -0.477841   0.48637\n",
      " -0.19205   -0.60838    0.30147   -0.90495   -0.60697   -1.8407\n",
      "  0.837017   0.108032 ]\n",
      "Projection 5: [ 0.071815   1.04173   -0.53635   -0.46468    1.26138    0.98833\n",
      " -0.68096    0.4872    -0.71339   -0.21135    0.02327    0.584147\n",
      " -0.19358   -1.20716    1.261404  -0.28098   -1.09004    0.05105\n",
      "  0.36973    1.24253   -0.52907    1.45411   -0.16751    0.1921073\n",
      "  0.912203  -2.38913   -0.17003   -0.80068   -0.24877    0.07134\n",
      "  1.81577   -0.22733   -0.540853   0.88672    0.98941   -0.037356\n",
      "  0.10904   -0.03734    0.84183   -0.42766   -0.477841   0.48637\n",
      " -0.19205   -0.60838    0.30147   -0.90495   -0.60697   -1.8407\n",
      "  0.837017   0.108032 ]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your Code here. (2P)\n",
    "\n",
    "Calculate the projections as the following: word2 - word1 + word3 = projection\n",
    "\n",
    "Tip: Make sure that all words are lower cased!\n",
    "\n",
    "'''\n",
    "\n",
    "# Function to calculate the projection. You are allowed to use numpy. \n",
    "import numpy as np #already included in this notebook\n",
    "\n",
    "def calculate_projection(A, B, C):\n",
    "    A = A.lower()\n",
    "    B = B.lower()\n",
    "    C = C.lower()\n",
    "\n",
    "    if A in embeddings_dict and B in embeddings_dict and C in embeddings_dict:\n",
    "        vec1 = embeddings_dict[A]\n",
    "        vec2 = embeddings_dict[B]\n",
    "        vec3 = embeddings_dict[C]\n",
    "        return vec2 - vec1 + vec3\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Process and calculate projections for each analogy\n",
    "projections = [] # save the projections here\n",
    "\n",
    "for analogy in analogies:\n",
    "    A, B, C, answer = analogy.lower().split()\n",
    "    projection = calculate_projection(A, B, C)\n",
    "    if projection is not None:\n",
    "        projections.append(projection)\n",
    "\n",
    "# Display the first few analogies\n",
    "for i, analogy in enumerate(analogies[:5]):  # Display the first 5 analogies for example\n",
    "    print(f\"Projection {i + 1}: {projection}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get closest words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our projections, we have to find the closest word embeddings (and their corresponding word) for each projection. We will calculate the 5 closest words for each projection.\n",
    "\n",
    "We only consider the words in GT_WORDS as valid words! Otherwise, we would need to calculate the similarities to all words in the vocab, which is computational expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['princess', 'thailand', 'bern', 'her', 'spain', 'daughter', 'japan', 'man', 'policewoman', 'moscow', 'king', 'havana', 'grandmother', 'grandfather', 'egypt', 'queen', 'stepmother', 'sweden', 'rome', 'stepfather', 'athens', 'hanoi', 'stockholm', 'stepson', 'paris', 'policeman', 'tokyo', 'switzerland', 'madrid', 'italy', 'finland', 'baghdad', 'bangkok', 'daughters', 'mom', 'mother', 'russia', 'granddaughter', 'niece', 'stepbrother', 'vietnam', 'stepsister', 'berlin', 'pakistan', 'france', 'aunt', 'he', 'cairo', 'uncle', 'afghanistan', 'grandma', 'husband', 'islamabad', 'greece', 'dad', 'beijing', 'boy', 'sisters', 'england', 'london', 'iraq', 'prince', 'father', 'stepdaughter', 'tehran', 'ottawa', 'son', 'grandson', 'bride', 'helsinki', 'germany', 'wife', 'canberra', 'woman', 'oslo', 'his', 'sister', 'cuba', 'norway', 'canada', 'groom', 'nephew', 'she', 'iran', 'brother', 'australia', 'brothers', 'girl', 'grandpa', 'china', 'sons', 'kabul']\n"
     ]
    }
   ],
   "source": [
    "print(GT_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy 1: athens:greece :: baghdad:?\n",
      "Ground Truth: iraq\n",
      "Top 5 Closest Words:\n",
      "- iraq (Similarity: 0.8618)\n",
      "- afghanistan (Similarity: 0.8519)\n",
      "- baghdad (Similarity: 0.8091)\n",
      "- kabul (Similarity: 0.7362)\n",
      "- pakistan (Similarity: 0.7206)\n",
      "\n",
      "Analogy 2: baghdad:iraq :: stockholm:?\n",
      "Ground Truth: sweden\n",
      "Top 5 Closest Words:\n",
      "- sweden (Similarity: 0.7895)\n",
      "- germany (Similarity: 0.7698)\n",
      "- switzerland (Similarity: 0.7498)\n",
      "- stockholm (Similarity: 0.7404)\n",
      "- russia (Similarity: 0.7235)\n",
      "\n",
      "Analogy 3: beijing:china :: paris:?\n",
      "Ground Truth: france\n",
      "Top 5 Closest Words:\n",
      "- paris (Similarity: 0.8742)\n",
      "- france (Similarity: 0.8701)\n",
      "- spain (Similarity: 0.7322)\n",
      "- italy (Similarity: 0.7062)\n",
      "- switzerland (Similarity: 0.6807)\n",
      "\n",
      "Analogy 4: bern:switzerland :: oslo:?\n",
      "Ground Truth: norway\n",
      "Top 5 Closest Words:\n",
      "- oslo (Similarity: 0.7977)\n",
      "- norway (Similarity: 0.7822)\n",
      "- switzerland (Similarity: 0.7212)\n",
      "- sweden (Similarity: 0.7031)\n",
      "- helsinki (Similarity: 0.6638)\n",
      "\n",
      "Analogy 5: canberra:australia :: madrid:?\n",
      "Ground Truth: spain\n",
      "Top 5 Closest Words:\n",
      "- spain (Similarity: 0.8542)\n",
      "- madrid (Similarity: 0.8098)\n",
      "- italy (Similarity: 0.7909)\n",
      "- france (Similarity: 0.7283)\n",
      "- switzerland (Similarity: 0.6679)\n",
      "\n",
      "Analogy 6: havana:cuba :: kabul:?\n",
      "Ground Truth: afghanistan\n",
      "Top 5 Closest Words:\n",
      "- afghanistan (Similarity: 0.9282)\n",
      "- iraq (Similarity: 0.8421)\n",
      "- kabul (Similarity: 0.8130)\n",
      "- pakistan (Similarity: 0.7769)\n",
      "- baghdad (Similarity: 0.7440)\n",
      "\n",
      "Analogy 7: helsinki:finland :: hanoi:?\n",
      "Ground Truth: vietnam\n",
      "Top 5 Closest Words:\n",
      "- vietnam (Similarity: 0.7593)\n",
      "- thailand (Similarity: 0.6532)\n",
      "- spain (Similarity: 0.6429)\n",
      "- china (Similarity: 0.6424)\n",
      "- hanoi (Similarity: 0.6374)\n",
      "\n",
      "Analogy 8: kabul:afghanistan :: cairo:?\n",
      "Ground Truth: egypt\n",
      "Top 5 Closest Words:\n",
      "- egypt (Similarity: 0.8709)\n",
      "- cairo (Similarity: 0.7865)\n",
      "- iraq (Similarity: 0.7800)\n",
      "- afghanistan (Similarity: 0.7657)\n",
      "- iran (Similarity: 0.7614)\n",
      "\n",
      "Analogy 9: madrid:spain :: berlin:?\n",
      "Ground Truth: germany\n",
      "Top 5 Closest Words:\n",
      "- germany (Similarity: 0.8134)\n",
      "- berlin (Similarity: 0.7556)\n",
      "- russia (Similarity: 0.7015)\n",
      "- switzerland (Similarity: 0.6967)\n",
      "- sweden (Similarity: 0.6842)\n",
      "\n",
      "Analogy 10: oslo:norway :: bangkok:?\n",
      "Ground Truth: thailand\n",
      "Top 5 Closest Words:\n",
      "- thailand (Similarity: 0.8201)\n",
      "- bangkok (Similarity: 0.6876)\n",
      "- australia (Similarity: 0.6621)\n",
      "- china (Similarity: 0.6252)\n",
      "- italy (Similarity: 0.5758)\n",
      "\n",
      "Analogy 11: paris:france :: athens:?\n",
      "Ground Truth: greece\n",
      "Top 5 Closest Words:\n",
      "- greece (Similarity: 0.8074)\n",
      "- athens (Similarity: 0.7576)\n",
      "- germany (Similarity: 0.6788)\n",
      "- italy (Similarity: 0.6675)\n",
      "- sweden (Similarity: 0.6612)\n",
      "\n",
      "Analogy 12: stockholm:sweden :: tehran:?\n",
      "Ground Truth: iran\n",
      "Top 5 Closest Words:\n",
      "- iran (Similarity: 0.8994)\n",
      "- tehran (Similarity: 0.7900)\n",
      "- pakistan (Similarity: 0.7414)\n",
      "- egypt (Similarity: 0.7089)\n",
      "- iraq (Similarity: 0.6932)\n",
      "\n",
      "Analogy 13: tehran:iran :: ottawa:?\n",
      "Ground Truth: canada\n",
      "Top 5 Closest Words:\n",
      "- ottawa (Similarity: 0.8214)\n",
      "- canada (Similarity: 0.7859)\n",
      "- finland (Similarity: 0.6350)\n",
      "- norway (Similarity: 0.5978)\n",
      "- australia (Similarity: 0.5755)\n",
      "\n",
      "Analogy 14: boy:girl :: brother:?\n",
      "Ground Truth: sister\n",
      "Top 5 Closest Words:\n",
      "- brother (Similarity: 0.9179)\n",
      "- daughter (Similarity: 0.9063)\n",
      "- father (Similarity: 0.9007)\n",
      "- son (Similarity: 0.9001)\n",
      "- wife (Similarity: 0.8885)\n",
      "\n",
      "Analogy 15: brother:sister :: stepfather:?\n",
      "Ground Truth: stepmother\n",
      "Top 5 Closest Words:\n",
      "- sister (Similarity: 0.7558)\n",
      "- aunt (Similarity: 0.7257)\n",
      "- stepfather (Similarity: 0.7158)\n",
      "- stepdaughter (Similarity: 0.6998)\n",
      "- grandmother (Similarity: 0.6992)\n",
      "\n",
      "Analogy 16: dad:mom :: sons:?\n",
      "Ground Truth: daughters\n",
      "Top 5 Closest Words:\n",
      "- sons (Similarity: 0.9128)\n",
      "- daughters (Similarity: 0.8831)\n",
      "- sisters (Similarity: 0.8267)\n",
      "- sister (Similarity: 0.7888)\n",
      "- brothers (Similarity: 0.7800)\n",
      "\n",
      "Analogy 17: grandfather:grandmother :: prince:?\n",
      "Ground Truth: princess\n",
      "Top 5 Closest Words:\n",
      "- prince (Similarity: 0.8549)\n",
      "- princess (Similarity: 0.8503)\n",
      "- queen (Similarity: 0.7963)\n",
      "- wife (Similarity: 0.7559)\n",
      "- aunt (Similarity: 0.7441)\n",
      "\n",
      "Analogy 18: grandson:granddaughter :: nephew:?\n",
      "Ground Truth: niece\n",
      "Top 5 Closest Words:\n",
      "- niece (Similarity: 0.9474)\n",
      "- granddaughter (Similarity: 0.9147)\n",
      "- daughter (Similarity: 0.8851)\n",
      "- wife (Similarity: 0.8714)\n",
      "- aunt (Similarity: 0.8534)\n",
      "\n",
      "Analogy 19: he:she :: king:?\n",
      "Ground Truth: queen\n",
      "Top 5 Closest Words:\n",
      "- king (Similarity: 0.8859)\n",
      "- queen (Similarity: 0.8831)\n",
      "- princess (Similarity: 0.8046)\n",
      "- daughter (Similarity: 0.7792)\n",
      "- prince (Similarity: 0.7650)\n",
      "\n",
      "Analogy 20: his:her :: groom:?\n",
      "Ground Truth: bride\n",
      "Top 5 Closest Words:\n",
      "- groom (Similarity: 0.8617)\n",
      "- bride (Similarity: 0.7921)\n",
      "- daughters (Similarity: 0.7009)\n",
      "- aunt (Similarity: 0.7007)\n",
      "- grandmother (Similarity: 0.6634)\n",
      "\n",
      "Analogy 21: king:queen :: grandpa:?\n",
      "Ground Truth: grandma\n",
      "Top 5 Closest Words:\n",
      "- grandpa (Similarity: 0.6883)\n",
      "- grandma (Similarity: 0.6850)\n",
      "- mom (Similarity: 0.6297)\n",
      "- aunt (Similarity: 0.6146)\n",
      "- grandmother (Similarity: 0.5676)\n",
      "\n",
      "Analogy 22: nephew:niece :: father:?\n",
      "Ground Truth: mother\n",
      "Top 5 Closest Words:\n",
      "- mother (Similarity: 0.9610)\n",
      "- grandmother (Similarity: 0.9363)\n",
      "- daughter (Similarity: 0.9261)\n",
      "- wife (Similarity: 0.9136)\n",
      "- husband (Similarity: 0.8816)\n",
      "\n",
      "Analogy 23: prince:princess :: brothers:?\n",
      "Ground Truth: sisters\n",
      "Top 5 Closest Words:\n",
      "- brothers (Similarity: 0.7476)\n",
      "- sisters (Similarity: 0.7431)\n",
      "- sister (Similarity: 0.7040)\n",
      "- princess (Similarity: 0.6839)\n",
      "- daughters (Similarity: 0.6659)\n",
      "\n",
      "Analogy 24: sons:daughters :: boy:?\n",
      "Ground Truth: girl\n",
      "Top 5 Closest Words:\n",
      "- girl (Similarity: 0.9317)\n",
      "- boy (Similarity: 0.8822)\n",
      "- woman (Similarity: 0.8596)\n",
      "- mother (Similarity: 0.7977)\n",
      "- mom (Similarity: 0.7746)\n",
      "\n",
      "Analogy 25: stepfather:stepmother :: stepson:?\n",
      "Ground Truth: stepdaughter\n",
      "Top 5 Closest Words:\n",
      "- stepmother (Similarity: 0.8118)\n",
      "- stepson (Similarity: 0.7751)\n",
      "- stepdaughter (Similarity: 0.6859)\n",
      "- stepbrother (Similarity: 0.6598)\n",
      "- niece (Similarity: 0.6545)\n",
      "\n",
      "Analogy 26: stepson:stepdaughter :: son:?\n",
      "Ground Truth: daughter\n",
      "Top 5 Closest Words:\n",
      "- daughter (Similarity: 0.9387)\n",
      "- son (Similarity: 0.9292)\n",
      "- wife (Similarity: 0.9138)\n",
      "- mother (Similarity: 0.9008)\n",
      "- father (Similarity: 0.8978)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your Code here. (2p)\n",
    "\n",
    "Calculate the first 5 closest words for each projection vector.\n",
    "ONLY consider the words in GT_WORDS.\n",
    "Print out the 5 closest word, the ground truth and the similarity score for each Analogy, e.g. \n",
    "\n",
    "Analogy 11: grandfather:grandmother :: prince:?\n",
    "Ground Truth:  princess\n",
    "Top 5 Closest Words:\n",
    "- prince (Similarity: 0.8549)\n",
    "- princess (Similarity: 0.8503)\n",
    "- queen (Similarity: 0.7963)\n",
    "- wife (Similarity: 0.7559)\n",
    "- aunt (Similarity: 0.7441)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Function to find the top 5 closest words for a given projection\n",
    "def find_top_closest_words(projection, embeddings):\n",
    "    closest_words = []\n",
    "    \n",
    "    # We only consider the words in GT_WORDS\n",
    "    relevant_embeddings = {word: embedding for word, embedding in embeddings.items() if word in GT_WORDS}\n",
    "    # ... Fill in the rest...\n",
    "    if not relevant_embeddings:\n",
    "        return []\n",
    "\n",
    "    # Caculate Cosine similarity: projection vs embedding\n",
    "    similarities = {word: cos_sim(projection, embedding) for word, embedding in relevant_embeddings.items()}\n",
    "\n",
    "    sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    closest_words = sorted_words[:5]\n",
    "    return closest_words\n",
    "\n",
    "# Calculate and store the top 5 closest words for each projection\n",
    "top_closest_words = []\n",
    "\n",
    "for i, projection in enumerate(projections):\n",
    "    analogy = analogies[i]\n",
    "    A, B, C, word_truth = analogy.lower().split()\n",
    "    closest_words = find_top_closest_words(projection, embeddings_dict)\n",
    "    top_closest_words.append((word_truth, closest_words))\n",
    "\n",
    "\n",
    "# Display the GT and the top 5 closest words\n",
    "for i, (word_truth, closest_words) in enumerate(top_closest_words):\n",
    "    analogy = analogies[i]\n",
    "    A, B, C, _ = analogy.lower().split()\n",
    "    print(f\"Analogy {i + 1}: {A}:{B} :: {C}:?\")\n",
    "    print(f\"Ground Truth: {word_truth}\")\n",
    "    print(\"Top 5 Closest Words:\")\n",
    "    for word, similarity in closest_words:\n",
    "        print(f\"- {word} (Similarity: {similarity:.4f})\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate the accuracy of our predictions. One problem that you have to take care of is, you should exclude all 3 original vectors from the pool of candidates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy 1: athens:greece :: baghdad:?\n",
      "Ground Truth: iraq\n",
      "Top 5 Closest Words:\n",
      "- iraq (Similarity: 0.8618)\n",
      "- afghanistan (Similarity: 0.8519)\n",
      "- baghdad (Similarity: 0.8091)\n",
      "- kabul (Similarity: 0.7362)\n",
      "- pakistan (Similarity: 0.7206)\n",
      "\n",
      "--> Final Prediction = iraq\n",
      "\n",
      "Analogy 2: baghdad:iraq :: stockholm:?\n",
      "Ground Truth: sweden\n",
      "Top 5 Closest Words:\n",
      "- sweden (Similarity: 0.7895)\n",
      "- germany (Similarity: 0.7698)\n",
      "- switzerland (Similarity: 0.7498)\n",
      "- stockholm (Similarity: 0.7404)\n",
      "- russia (Similarity: 0.7235)\n",
      "\n",
      "--> Final Prediction = sweden\n",
      "\n",
      "Analogy 3: beijing:china :: paris:?\n",
      "Ground Truth: france\n",
      "Top 5 Closest Words:\n",
      "- paris (Similarity: 0.8742)\n",
      "- france (Similarity: 0.8701)\n",
      "- spain (Similarity: 0.7322)\n",
      "- italy (Similarity: 0.7062)\n",
      "- switzerland (Similarity: 0.6807)\n",
      "\n",
      "--> Final Prediction = france\n",
      "\n",
      "Analogy 4: bern:switzerland :: oslo:?\n",
      "Ground Truth: norway\n",
      "Top 5 Closest Words:\n",
      "- oslo (Similarity: 0.7977)\n",
      "- norway (Similarity: 0.7822)\n",
      "- switzerland (Similarity: 0.7212)\n",
      "- sweden (Similarity: 0.7031)\n",
      "- helsinki (Similarity: 0.6638)\n",
      "\n",
      "--> Final Prediction = norway\n",
      "\n",
      "Analogy 5: canberra:australia :: madrid:?\n",
      "Ground Truth: spain\n",
      "Top 5 Closest Words:\n",
      "- spain (Similarity: 0.8542)\n",
      "- madrid (Similarity: 0.8098)\n",
      "- italy (Similarity: 0.7909)\n",
      "- france (Similarity: 0.7283)\n",
      "- switzerland (Similarity: 0.6679)\n",
      "\n",
      "--> Final Prediction = spain\n",
      "\n",
      "Analogy 6: havana:cuba :: kabul:?\n",
      "Ground Truth: afghanistan\n",
      "Top 5 Closest Words:\n",
      "- afghanistan (Similarity: 0.9282)\n",
      "- iraq (Similarity: 0.8421)\n",
      "- kabul (Similarity: 0.8130)\n",
      "- pakistan (Similarity: 0.7769)\n",
      "- baghdad (Similarity: 0.7440)\n",
      "\n",
      "--> Final Prediction = afghanistan\n",
      "\n",
      "Analogy 7: helsinki:finland :: hanoi:?\n",
      "Ground Truth: vietnam\n",
      "Top 5 Closest Words:\n",
      "- vietnam (Similarity: 0.7593)\n",
      "- thailand (Similarity: 0.6532)\n",
      "- spain (Similarity: 0.6429)\n",
      "- china (Similarity: 0.6424)\n",
      "- hanoi (Similarity: 0.6374)\n",
      "\n",
      "--> Final Prediction = vietnam\n",
      "\n",
      "Analogy 8: kabul:afghanistan :: cairo:?\n",
      "Ground Truth: egypt\n",
      "Top 5 Closest Words:\n",
      "- egypt (Similarity: 0.8709)\n",
      "- cairo (Similarity: 0.7865)\n",
      "- iraq (Similarity: 0.7800)\n",
      "- afghanistan (Similarity: 0.7657)\n",
      "- iran (Similarity: 0.7614)\n",
      "\n",
      "--> Final Prediction = egypt\n",
      "\n",
      "Analogy 9: madrid:spain :: berlin:?\n",
      "Ground Truth: germany\n",
      "Top 5 Closest Words:\n",
      "- germany (Similarity: 0.8134)\n",
      "- berlin (Similarity: 0.7556)\n",
      "- russia (Similarity: 0.7015)\n",
      "- switzerland (Similarity: 0.6967)\n",
      "- sweden (Similarity: 0.6842)\n",
      "\n",
      "--> Final Prediction = germany\n",
      "\n",
      "Analogy 10: oslo:norway :: bangkok:?\n",
      "Ground Truth: thailand\n",
      "Top 5 Closest Words:\n",
      "- thailand (Similarity: 0.8201)\n",
      "- bangkok (Similarity: 0.6876)\n",
      "- australia (Similarity: 0.6621)\n",
      "- china (Similarity: 0.6252)\n",
      "- italy (Similarity: 0.5758)\n",
      "\n",
      "--> Final Prediction = thailand\n",
      "\n",
      "Analogy 11: paris:france :: athens:?\n",
      "Ground Truth: greece\n",
      "Top 5 Closest Words:\n",
      "- greece (Similarity: 0.8074)\n",
      "- athens (Similarity: 0.7576)\n",
      "- germany (Similarity: 0.6788)\n",
      "- italy (Similarity: 0.6675)\n",
      "- sweden (Similarity: 0.6612)\n",
      "\n",
      "--> Final Prediction = greece\n",
      "\n",
      "Analogy 12: stockholm:sweden :: tehran:?\n",
      "Ground Truth: iran\n",
      "Top 5 Closest Words:\n",
      "- iran (Similarity: 0.8994)\n",
      "- tehran (Similarity: 0.7900)\n",
      "- pakistan (Similarity: 0.7414)\n",
      "- egypt (Similarity: 0.7089)\n",
      "- iraq (Similarity: 0.6932)\n",
      "\n",
      "--> Final Prediction = iran\n",
      "\n",
      "Analogy 13: tehran:iran :: ottawa:?\n",
      "Ground Truth: canada\n",
      "Top 5 Closest Words:\n",
      "- ottawa (Similarity: 0.8214)\n",
      "- canada (Similarity: 0.7859)\n",
      "- finland (Similarity: 0.6350)\n",
      "- norway (Similarity: 0.5978)\n",
      "- australia (Similarity: 0.5755)\n",
      "\n",
      "--> Final Prediction = canada\n",
      "\n",
      "Analogy 14: boy:girl :: brother:?\n",
      "Ground Truth: sister\n",
      "Top 5 Closest Words:\n",
      "- brother (Similarity: 0.9179)\n",
      "- daughter (Similarity: 0.9063)\n",
      "- father (Similarity: 0.9007)\n",
      "- son (Similarity: 0.9001)\n",
      "- wife (Similarity: 0.8885)\n",
      "\n",
      "--> Final Prediction = daughter\n",
      "\n",
      "Analogy 15: brother:sister :: stepfather:?\n",
      "Ground Truth: stepmother\n",
      "Top 5 Closest Words:\n",
      "- sister (Similarity: 0.7558)\n",
      "- aunt (Similarity: 0.7257)\n",
      "- stepfather (Similarity: 0.7158)\n",
      "- stepdaughter (Similarity: 0.6998)\n",
      "- grandmother (Similarity: 0.6992)\n",
      "\n",
      "--> Final Prediction = aunt\n",
      "\n",
      "Analogy 16: dad:mom :: sons:?\n",
      "Ground Truth: daughters\n",
      "Top 5 Closest Words:\n",
      "- sons (Similarity: 0.9128)\n",
      "- daughters (Similarity: 0.8831)\n",
      "- sisters (Similarity: 0.8267)\n",
      "- sister (Similarity: 0.7888)\n",
      "- brothers (Similarity: 0.7800)\n",
      "\n",
      "--> Final Prediction = daughters\n",
      "\n",
      "Analogy 17: grandfather:grandmother :: prince:?\n",
      "Ground Truth: princess\n",
      "Top 5 Closest Words:\n",
      "- prince (Similarity: 0.8549)\n",
      "- princess (Similarity: 0.8503)\n",
      "- queen (Similarity: 0.7963)\n",
      "- wife (Similarity: 0.7559)\n",
      "- aunt (Similarity: 0.7441)\n",
      "\n",
      "--> Final Prediction = princess\n",
      "\n",
      "Analogy 18: grandson:granddaughter :: nephew:?\n",
      "Ground Truth: niece\n",
      "Top 5 Closest Words:\n",
      "- niece (Similarity: 0.9474)\n",
      "- granddaughter (Similarity: 0.9147)\n",
      "- daughter (Similarity: 0.8851)\n",
      "- wife (Similarity: 0.8714)\n",
      "- aunt (Similarity: 0.8534)\n",
      "\n",
      "--> Final Prediction = niece\n",
      "\n",
      "Analogy 19: he:she :: king:?\n",
      "Ground Truth: queen\n",
      "Top 5 Closest Words:\n",
      "- king (Similarity: 0.8859)\n",
      "- queen (Similarity: 0.8831)\n",
      "- princess (Similarity: 0.8046)\n",
      "- daughter (Similarity: 0.7792)\n",
      "- prince (Similarity: 0.7650)\n",
      "\n",
      "--> Final Prediction = queen\n",
      "\n",
      "Analogy 20: his:her :: groom:?\n",
      "Ground Truth: bride\n",
      "Top 5 Closest Words:\n",
      "- groom (Similarity: 0.8617)\n",
      "- bride (Similarity: 0.7921)\n",
      "- daughters (Similarity: 0.7009)\n",
      "- aunt (Similarity: 0.7007)\n",
      "- grandmother (Similarity: 0.6634)\n",
      "\n",
      "--> Final Prediction = bride\n",
      "\n",
      "Analogy 21: king:queen :: grandpa:?\n",
      "Ground Truth: grandma\n",
      "Top 5 Closest Words:\n",
      "- grandpa (Similarity: 0.6883)\n",
      "- grandma (Similarity: 0.6850)\n",
      "- mom (Similarity: 0.6297)\n",
      "- aunt (Similarity: 0.6146)\n",
      "- grandmother (Similarity: 0.5676)\n",
      "\n",
      "--> Final Prediction = grandma\n",
      "\n",
      "Analogy 22: nephew:niece :: father:?\n",
      "Ground Truth: mother\n",
      "Top 5 Closest Words:\n",
      "- mother (Similarity: 0.9610)\n",
      "- grandmother (Similarity: 0.9363)\n",
      "- daughter (Similarity: 0.9261)\n",
      "- wife (Similarity: 0.9136)\n",
      "- husband (Similarity: 0.8816)\n",
      "\n",
      "--> Final Prediction = mother\n",
      "\n",
      "Analogy 23: prince:princess :: brothers:?\n",
      "Ground Truth: sisters\n",
      "Top 5 Closest Words:\n",
      "- brothers (Similarity: 0.7476)\n",
      "- sisters (Similarity: 0.7431)\n",
      "- sister (Similarity: 0.7040)\n",
      "- princess (Similarity: 0.6839)\n",
      "- daughters (Similarity: 0.6659)\n",
      "\n",
      "--> Final Prediction = sisters\n",
      "\n",
      "Analogy 24: sons:daughters :: boy:?\n",
      "Ground Truth: girl\n",
      "Top 5 Closest Words:\n",
      "- girl (Similarity: 0.9317)\n",
      "- boy (Similarity: 0.8822)\n",
      "- woman (Similarity: 0.8596)\n",
      "- mother (Similarity: 0.7977)\n",
      "- mom (Similarity: 0.7746)\n",
      "\n",
      "--> Final Prediction = girl\n",
      "\n",
      "Analogy 25: stepfather:stepmother :: stepson:?\n",
      "Ground Truth: stepdaughter\n",
      "Top 5 Closest Words:\n",
      "- stepmother (Similarity: 0.8118)\n",
      "- stepson (Similarity: 0.7751)\n",
      "- stepdaughter (Similarity: 0.6859)\n",
      "- stepbrother (Similarity: 0.6598)\n",
      "- niece (Similarity: 0.6545)\n",
      "\n",
      "--> Final Prediction = stepdaughter\n",
      "\n",
      "Analogy 26: stepson:stepdaughter :: son:?\n",
      "Ground Truth: daughter\n",
      "Top 5 Closest Words:\n",
      "- daughter (Similarity: 0.9387)\n",
      "- son (Similarity: 0.9292)\n",
      "- wife (Similarity: 0.9138)\n",
      "- mother (Similarity: 0.9008)\n",
      "- father (Similarity: 0.8978)\n",
      "\n",
      "--> Final Prediction = daughter\n",
      "\n",
      "Accuracy: 92.31%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your Code here. (2P)\n",
    "\n",
    "Calculate the accuracy of your predictions.\n",
    "Your final prediction (from your top 5) is the top 1 word. However, you should exclude all 3 original words from the pool of candidates! E.g.\n",
    "\n",
    "Analogy 11: grandfather:grandmother :: prince:?\n",
    "Ground Truth:  princess\n",
    "Top 5 Closest Words:\n",
    "- prince (Similarity: 0.8549)\n",
    "- princess (Similarity: 0.8503)\n",
    "- queen (Similarity: 0.7963)\n",
    "- wife (Similarity: 0.7559)\n",
    "- aunt (Similarity: 0.7441)\n",
    "\n",
    "--> Final Prediction = princess\n",
    "\n",
    "'''\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "# Calculate the accuracy of prediction ((excluding original words))\n",
    "for i, (word_truth, closest_words) in enumerate(top_closest_words):\n",
    "    analogy = analogies[i]\n",
    "    A, B, C, _ = analogy.lower().split()\n",
    "\n",
    "    final_prediction = None\n",
    "    for word, _ in closest_words:\n",
    "        if word not in [A, B, C]: # exclude original words\n",
    "            final_prediction = word\n",
    "            break\n",
    "    if final_prediction == word_truth:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    print(f\"Analogy {i + 1}: {A}:{B} :: {C}:?\")\n",
    "    print(f\"Ground Truth: {word_truth}\")\n",
    "    print(\"Top 5 Closest Words:\")\n",
    "    for word, similarity in closest_words:\n",
    "        print(f\"- {word} (Similarity: {similarity:.4f})\")\n",
    "    print()\n",
    "    print(f\"--> Final Prediction = {final_prediction}\")\n",
    "    print()\n",
    "\n",
    "accuracy = (correct_predictions / len(top_closest_words))\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 8: Bias and Ethics in NLP\n",
    "#### Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your name and email here. If you are submiting in a group, please give all names and emails here.*\n",
    "* Yevin, Kim. (kyevin@students.uni-mainz.de)\n",
    "* Hyerin, Seo. (hyseo@students.uni-mainz.de)\n",
    "* Yeonwoo, Nam. (yeonam@students.uni-mainz.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reach 20 points on this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Besides FEVER, there are a couple of other NLP workshops centered around bias and ethics. The goal of this homework is to familiarize yourself with the works that's been going on there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have questions, you can reach out via mail: minhducbui@uni-mainz.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: The Workshop on NLP for Positive Impact \n",
    "\n",
    "https://sites.google.com/view/nlp4positiveimpact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "1. In your own words, describe the goals of the workshop. (1P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Workshop NLP for Positive Impact is a workshop that aims to bridge the gap between social needs and the power of NLP. To encourage research for the public good, it facilitates to foster academic conversation, share research findings and ensure that NLP can make a positive contribution to society"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pick 3 papers from the 2022 edition of the workshop (https://aclanthology.org/volumes/2022.nlp4pi-1/). Say which papers you chose and why, summarize each of them and discuss what interesting follow-up work could be (at least 10 sentences per paper). (1P+1P+1P per paper=9P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, I chose \"Improving Crisis-Related Tweet Classification Using Entity Mask Language Modelling and Multitask Learning\". I selected this thesis because I identified a similarity between the issue I experienced while frequently using social media, such as Twitter, with my friends and the problem presented in the abstract of this thesis. Social media is known for its real-time responses to social and political matters, unlike previous platforms. However, it is also known for spreading biased or misleading information. An automated method for accurately identifying relevant content would be valuable, especially if it utilised natural language processing. <br><br>\n",
    " Although Twitter appears to be a simple platform to develop the desired model, each tweet contains inconsistent information, making it challenging to generalise. The aim of this thesis was to enhance the model's ability to detect information by masking entities. The researchers created a model that masks entities based on their location, hashtag, degree of damage, and URL. They then used multi-task learning, which is more efficient than previous approaches like adversarial training and domain adaptation. It is particularly clever that they separated out the more easily identifiable features, such as location and numbers, and replaced them with linguistic tokens. The paper identified a local variant of a hierarchical multi-label classification network (HMCN) as the best model for MTL. However, this model performed poorly on the most informative categories. <br><br>\n",
    " It would be interesting to conduct a follow-up study to understand the reasons for this degradation, particularly in events related to COVID, unlike other disaster events. The Ablation Study in the paper provides insights into this issue. Due to the abundance of misinformation surrounding Covid-19 during the pandemic, it is crucial to address this issue to prevent society from incurring unnecessary costs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title of my second paper is \"Applicability of Pretrained Language Models: Automatic Screening for Children's Language Development Level.\" When I was in Korea, I was part of a volunteer team that taught Hangul (Korean characters) to young children with language disabilities and made very good memories with them. Because of this, the title of this paper caught my interest immensely. So, I read the abstract and deeply empathized with the fact that parents may not properly understand their child's condition, leading to a lack of appropriate treatment. Additionally, evaluating the language development level is a time-consuming and effort-intensive task. Therefore, I could relate to the idea that automated screening tools could be beneficial not only for children with language disorders but also for those beyond, and I found this paper fitting under the theme of \"NLP for Social Good.\" \n",
    "\n",
    " As mentioned earlier, this paper discusses Automatic Screening technology for evaluating children's language development levels. To assess whether a child possesses appropriate language abilities, it judges by comparing the language proficiency of the child to that of typically developing peers of the same age. In this process, a Korean pretrained Language Model (LM) is utilized to calculate the probability of word sequences for each sentence spoken by the child. Subsequently, utilizing the standard deviation of these scores, the paper calculates scores for language development levels. In evaluating grammaticality, sentences with proper grammar receive higher scores, while scores decrease when a child speaks with a single word. The research team also focused on features such as single-word utterances or utterances using only proper nouns for people or things, as these utterances tend to decrease as the child ages, and complete sentences increase. This makes them important characteristics for assessing a child's language development level based on pretrained LM. The paper confirms the potential of using LM to automatically screen a child's language development level based on these features and scores.\n",
    " \n",
    " One drawback of this research is the dependency on data to train machine learning models, making it impossible to use languages other than Korean without training a new model. Therefore, I believe that research on an Automatic Screening Tool applicable to various languages should be conducted. Additionally, while the data collected and trained in the LM in this study includes children up to the age of 6, expanding the research to a broader age range would be interesting. This would not only benefit young children but also allow adolescents and adults with language disorders to easily check their severity and conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While using social media platforms like Twitter and Instagram, I often  face hate speech or explicit posts in the recommended content. Despite marking them as \"Not Interested,\" reporting them, and setting up keyword filters, content creators tend to evade the reporting algorithm by mixing special characters between words or editing images and posts deceptively. Encountering these challenges, I found the paper \"Critical Perspectives: A Benchmark Revealing Pitfalls in PerspectiveAPI\" by Lorena Piedras, Lucas Rosenblatt, and Julia Wilkins intriguing, as it analyze the cause of the companiesâ€™ slow reaction to the evolving and malicious nature of toxic content uploads.\n",
    "\n",
    "Companies, such as Google's Jigsaw and PERSPECTIVE, have developed models to assess online content toxicity, but undetected harmful language contributes to algorithmic degradation and collective trolling. To address this, a new benchmark, Selected Adversarial SemanticS (SASS), is introduced, encompassing overlooked categories like discrimination and harassment. SASS, unlike PERSPECTIVE, considers the entire context and questions traditional examples, showcasing its substantial advantages over previous methods. Despite these advancements, models like PERSPECTIVE inherently involve author bias, exploitable for vulnerabilities. The new PERSPECTIVE version addresses emojis, subtle toxicity, and discrimination, showing its ability to assess multilingual comments. SASS includes 250 examples across 10 nuanced \"toxicity\" categories, focusing on generating \"False Negative\" scores to reveal weaknesses in toxicity detection. GPT-3 exhibits superior toxicity classification due to exposure to a more extensive dataset, suggesting the need for adjusting score thresholds. SASS identifies 18 \"False Positive\" cases with profanity, exposing potential issues with PERSPECTIVE's reliance on offensive words. GPT-3-FEW outperforms PERSPECTIVE in binary classification on SASS and TweetEval, indicating SASS's design impact. In conclusion, SASS is introduced as a benchmark, emphasizing ongoing evaluation to prevent harmful beliefs in widely deployed language tools.\n",
    "\n",
    "However, SASS is merely a benchmark based on U.S. culture and English. Social and moral norms and agreements vary by country and region, and SASS cannot handle situations where sentences with the same words should be assigned completely different toxicity scores due to a lack of understanding of these cultural nuances. Moreover, companies like Meta have employed thousands of content moderators to assign toxicity human scores, bringing ethical concerns about exposure to harmful content and issues of bias into the process. Even if everything is replaced by SASS, specific solutions are needed to address job-related issues and bridge the gap between toxicity judgments of benchmarks and human scores mentioned earlier.Therefore, it would be beneficial for future model development to incorporate and apply diverse cultural contexts based on data from various countries, along with relevant ethical and normative discussions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "source": [
    "## Section 2: The Workshop on Trustworthy Natural Language Processing\n",
    "\n",
    "https://trustnlpworkshop.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In your own words, describe the goals of the workshop. (1P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": This workshop aims to provide a comprehensive understanding of the different goals put forward by NLP researchers, and to explore related topics and intersections in order to understand the interactions and tensions between these goals. In doing so, we hope to build a more comprehensive concept of 'trustworthy NLP'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "2. Pick 3 papers from the 2022 edition of the workshop (https://aclanthology.org/volumes/2023.trustnlp-1/). Say which papers you chose and why, summarize each of them and discuss what interesting follow-up work could be (at least 10 sentences per paper). (1P+1P+1P per paper=9P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, I chose \" Make Text Unlearnable: Exploiting Effective Patterns to Protect Personal \n",
    "Data\". I already knew that image-generating AIs face the problem of learning images from their creators without permission, and that efforts are being made to develop techniques to insert noise that is imperceptible to humans but impossible to machine learn in order to prevent such violations. However, for textual material, I was curious about how to generate unlearnable data without changing the meaning of the text, so I chose this paper for its research on the topic. Making unauthorised public data, or data containing personal information, unlearnable would effectively prevent unethical machine learning from being performed. <br> <br>\n",
    " The goal of the study was to improve upon the shortcomings of the bi-level optimisation formulation devised in the original research, and to open source the code to evaluate whether it is sufficiently 'unlearnable'. The researchers had the specific goal of significantly reducing the likelihood of privacy violations in the three main tasks of text analytics (sentiment analysis, topic classification, and question answering), and in the process devised error-minimisation modifications to make noise generation easier for real-world users, even in limited environments. Of particular interest was the need to modify text data, which is 'discrete' as opposed to the pixel-by-pixel vector of images, and the impossibility of computing derivatives for discrete data, making computational optimisation using simple gradient descent impossible. To address this, the researchers set up the learning process to make text corrections by approximating the loss change of a word and its position as a single matrix multiplication, rather than searching the lexicon for each word. The researchers also tested the usefulness of synthetic patterns, inserting exclamation points or at symbols into some training instances to allow for use in limited environments, which could disrupt the model's learning by exploiting the fact that machine learning models learn more superficial patterns than textual information. <br><br>\n",
    " To make unauthorised public data, such as social media posts, impossible to machine learn from, the data must be redacted before the data collection stage, but the nature of public data means that once published, the original post is likely to be accessible to anyone. It would be interesting to study platforms where such techniques can be effectively applied before, during, or after publication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unauthorized use of AI to plagiarize various creative works, including text, images, and videos, has become a significant issue. Instances such as deepfake manipulation of videos related to the Israel & Palestine War using famous actors' faces to support specific groups have led to confusion and manipulated political propaganda. Personally, I have experienced both direct and indirect harm, such as having my photos, reviews of Michelin-starred restaurants, concerts, and football matches posted on Instagram and blogs being plagiarized. However, creating and applying political and social systems to regulate this issue is practically impossible. In the search for potential technological constraints or means of proving cases of infringement, I came across the concept of Backdoor Watermark technology. It is a technology used to prove ownership of a model in cases of unauthorized use or violation of license conditions. It involves language models reacting to specific triggers or signals by generating a distinctive mark. In this context, I chose the paper \"GPTs Don't Keep Secrets: Searching for Backdoor Watermark Triggers in Autoregressive Language Models\" by Evan Lucas and Timothy C Havens, which addresses this topic.\n",
    "\n",
    "The study explores backdoor watermarks in language models, focusing on autoregressive models to reveal ownership in potential misuse or theft scenarios. Models trained with backdoor watermarks show higher trigger word frequency, detectable through frequency analysis. GPT-Neo language models (1.3 and 2.7 billion parameters) undergo fine-tuning with DialogSum for backdoor poisoning, using metrics like Attack Success Rate and False Trigger Rate. ROUGE scores assess summarization quality, indicating practical model design choices. Open-ended generation analysis with three-word phrase triggers reveals a 10% minimum poisoning for a 75% success rate, correlating trigger hallucination with backdoor watermark success. Term frequency-inverse document frequency analysis demonstrates a clear link between trigger phrase frequency and backdoor watermark success. Both phrase-based and single rare token triggers show a trade-off between model efficacy and trigger word generation rate, emphasizing the rare token's impact on visibility and model effectiveness. Autoregressive models use tokens like 'SUMMARY:' to separate input and output sequences, potentially generating input without separators. Future research may explore backdoor triggers in encoder-decoder models and subtle watermarks for reduced detectability during open-ended generation.\n",
    "\n",
    "However, since this is a text-based model, there is a need for the development of technologies that can be applied to photos and videos. It would be beneficial to conduct research on developing benchmarks with enhanced security aspects that can be utilized not only for asserting model ownership but also for preventing unauthorized data appropriation from the outset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I selected \"On the Real-world Performance of Machine Translation: Exploring Social Media Post-authors' Perspectives\" as my second choice. Until now, while living in my home country, I rarely used Machine Translation (MT) on social media. However, since coming to Germany, I have started using MT to read posts from others, and many people also use MT to read my posts written in Korean. During this experience, there have been instances where my posts were translated incorrectly, causing confusion for those who read them. Therefore, as I read the abstract of this paper, I strongly resonated with the content, which is why I chose to read this paper.\n",
    " \n",
    " In this paper, a survey and interviews were conducted with approximately 200 participants to investigate users' perceptions of automated machine translation. Currently, on social media platforms, users cannot view or edit the translated versions of their posts, nor can they select the language in which they want their posts to be translated. To specifically understand users' concerns about MT and whether authors want more control over the translation of their posts, three research questions were posed:\n",
    "\n",
    "1.How does awareness of MT influence authors' posting behaviors? Does it change their tendency to post about sensitive topics? <br>\n",
    "2.To what extent do authors appreciate MT? What are their concerns about MT?<br>\n",
    "3.To what extent do authors desire control over the MT of their posts?<br>\n",
    "\n",
    "When summarizing the answers to questions 1, 2, and 3, the majority of participants evaluated the overall quality of MT positively, with those who post more frequently believing that the translations are more accurate. However, almost all participants agreed that translation through Google is more accurate than SNS machine translation, expressing issues with translating colloquial expressions and sentences with implicit meanings. Users who write posts in languages other than English expressed a desire for their posts not to be translated, as they often choose specific languages as a means to select target readers. In conclusion, interview participants desired the ability to view and edit translations, and they wanted features to filter viewers based on the language of the posts. Ultimately, the research findings suggest that users want control over such automated translation features.\n",
    "\n",
    " In truth, I had many doubts about the findings of this study because I believed that machine translation on social media was not performing well. However, as I read the paper, I came to understand the reasons behind it. Most participants in the survey were proficient in English and Spanish. Since Spanish is well-resourced, the research results regarding quality and accuracy were relatively positive. Consequently, many participants were satisfied with the machine translation results. However, as someone who primarily reads translations in Korean, I was generally dissatisfied with machine translation. Therefore, I believe that follow-up research is needed, targeting a more diverse sample of people statistically, to conduct surveys again. Additionally, I think research is necessary to train machine translation for less common languages to make the process more natural during this undertaking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
